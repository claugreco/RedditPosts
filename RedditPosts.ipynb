{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Reddit & Predicting Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, we will practice two major skills. Collecting data by scraping a website and then building a binary predictor.\n",
    "\n",
    "As we discussed in week 2, and earlier today, there are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "For this article, your problem statement will be: _What characteristics of a post on Reddit contribute most to the overall interaction (as measured by number of comments)?_\n",
    "\n",
    "Your method for acquiring the data will be scraping the 'hot' threads as listed on the [Reddit homepage](https://www.reddit.com/). You'll acquire _AT LEAST FOUR_ pieces of information about each thread:\n",
    "1. The title of the thread\n",
    "2. The subreddit that the thread corresponds to\n",
    "3. The length of time it has been up on Reddit\n",
    "4. The number of comments on the thread\n",
    "\n",
    "Once you've got the data, you will build a classification model that, using Natural Language Processing and any other relevant features, predicts whether or not a given Reddit post will have above or below the _median_ number of comments.\n",
    "\n",
    "**BONUS PROBLEMS**\n",
    "1. If creating a logistic regression, GridSearch Ridge and Lasso for this model and report the best hyperparameter values.\n",
    "1. Scrape the actual text of the threads using Selenium (you'll learn about this in Webscraping II).\n",
    "2. Write the actual article that you're pitching and turn it into a blog post that you host on your personal website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping Thread Info from Reddit.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"http://www.reddit.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!doctype html><html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"en\" xml:lang=\"en\"><head><title>reddit: the front page of the internet</title><meta name=\"keywords\" content=\" reddit, reddit.com, vote, comment, submit \" /><meta name=\"description\" content=\"reddit: the front page of the internet\" /><meta name=\"referrer\" content=\"always\"><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /><link type=\"application/opensearchdescription+xml\" rel=\"search\" href=\"/static/opensearch.xml\"/><link rel=\"canonical\" href=\"https://www.reddit.com/\" /><meta name=\"viewport\" content=\"width=1024\"><link rel=\"dns-prefetch\" href=\"//out.reddit.com\"><link rel=\"preconnect\" href=\"//out.reddit.com\"><link re\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Project3-ClaudiaGreco',\n",
    "    'From': 'claugreco@gmail.com'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "#response = requests.get(url)\n",
    "\n",
    "print(response.status_code)\n",
    "\n",
    "html = response.text\n",
    "\n",
    "print(html[:700])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reddit: the front page of the internetr.setup({\"ajax_domain\": \"www.reddit.com\", \"poisoning_canary\": null, \"post_site\": \"\", \"gold\": false, \"poisoning_report_mac\": null, \"requires_eu_cookie_policy\": false, \"nsfw_media_acknowledged\": false, \"stats_domain\": \"https://stats.redditmedia.com\", \"feature_onboarding_splash\": \"active\", \"cur_screen_name\": \"\", \"feature_expando_events\": true, \"facebook_app_id\": \"322647334569188\", \"loid\": \"00000000000y7hxu52\", \"is_sponsor\": false, \"feature_autofill_username\": \"control_2\", \"user_id\": false, \"pref_email_messages\": false, \"feature_new_report_flow\": true, \"feature_subscribe_join_follow_test\": null, \"logged\": false, \"feature_heartbeat_events\": true, \"ads_loading_timeout_ms\": 5000, \"over_18\": false, \"feature_ads_user_matching\": false, \"external_frame\": false, \"mweb_blacklist_expressions\": [\"^/prefs/?\", \"^/live/?\", \"/message/compose\", \"/m/\", \"^/subreddits/create\", \"^/gold\", \"^/advertising\", \"^/promoted\", \"^/buttons\"], \"feature_hover_user_ui_holdout\": false, \"uitracker_url\": \"//pixel.redditmedia.com/pixel/of_discovery.png\", \"modhash\": \"\", \"loid_created\": 1519251973068, \"feature_net_neutrality\": false, \"send_logs\": true, \"user_subscription_size\": 0, \"listing_over_18\": false, \"https_endpoint\": \"https://www.reddit.com\", \"extension\": null, \"share_tracking_ts\": 1519251973195, \"enabled_experiments\": {}, \"event_target\": {\"geo_filter\": \"US_MA\", \"target_type\": \"listing\", \"target_sort\": \"hot\"}, \"advertiser_category\": null, \"expando_preference\": \"subreddit_default\", \"debug\": false, \"has_subscribed\": false, \"server_time\": 1519251973.0, \"clicktracker_url\": \"//pixel.redditmedia.com/click\", \"pref_no_profanity\": true, \"cur_site\": \"\", \"cur_domain\": \"reddit.com\", \"feature_new_report_dialog\": true, \"events_collector_url\": \"https://events.reddit.com/v1\", \"feature_flatlist_events\": false, \"feature_archived_signup_cta\": false, \"https_forced\": true, \"user_in_timeout\": false, \"share_tracking_hmac\": null, \"user_websocket_url\": null, \"ad_serving_events_sample_rate\": 1.0, \"is_fake\": true, \"renderstyle\": \"html\", \"feature_outbound_beacons\": false, \"feature_signup_cta_p5\": null, \"pref_no_video_autoplay\": false, \"user_age\": false, \"vote_hash\": \"KVE1QUDMZEyus/z4dhGfpajEG5O9jriHgtbw19lhJ0V60LSun6J4106xMnF4LeIyZCYb8G3h2GwRlHXV8FLyCtjonFWks5AKBcbtPpfj+JDPdMGpEMs5y6Pr133EtJXl5Rz9cmbIQ8VOkV1W1CjHGmzmmDIV8ukSICxVUuZImtI=\", \"events_collector_secret\": \"thiiM0ahsieSiech1phithe6chahngoo8sah6aid\\\\n\", \"eventtracker_url\": \"//pixel.redditmedia.com/pixel/of_delight.png\", \"events_collector_key\": \"RedditFrontend1\", \"feature_post_embed\": true, \"feature_mobile_native_banner\": true, \"feature_onboarding_email_username_switch\": \"control_2\", \"cache_policy\": \"loggedout_www\", \"feature_geopopular_onboarding\": null, \"events_collector_v2_url\": \"https://events.reddit.com/v2\", \"store_visits\": false, \"anon_eventtracker_url\": \"//pixel.redditmedia.com/pixel/of_diversity.png\", \"new_window\": false, \"pref_beta\": false, \"eu_cookie_max_attempts\": 3, \"pageInfo\": {\"actionName\": \"best.GET_listing\", \"statsVerification\": \"43fcc3f4d77e33d0417bf235aea1aa2c52ef0fd6\", \"verification\": \"43fcc3f4d77e33d0417bf235aea1aa2c52ef0fd6\", \"statsName\": \"best.GET_listing\"}, \"live_orangereds_pref\": true, \"media_domain\": \"www.redditmedia.com\", \"whitelist_status\": \"all_ads\", \"static_root\": \"//www.redditstatic.com\", \"feature_screenview_events\": true, \"cur_listing\": \"frontpage\", \"email_verified\": false, \"status_msg\": {\"fetching\": \"fetching title...\", \"loading\": \"loading...\", \"submitting\": \"submitting...\"}, \"stats_sample_rate\": \"5\", \"loid_version\": 2, \"eu_cookie\": \"eu_cookie\", \"feature_double_sidebar\": false, \"feature_scroll_events\": true})/* Custom css: use this block to insert special translation-dependent css in the page header */window.user_type = \\'guest\\'; window.is_gold_page = \\'False\\'.toLowerCase() === \\'true\\';var _gaq = _gaq || []; _gaq.push( [\\'_require\\', \\'inpage_linkid\\', \\'//www.google-analytics.com/plugins/ga/inpage_linkid.js\\'], [\\'_setAccount\\', \\'UA-12131688-1\\'], [\\'_setDomainName\\', \\'reddit.com\\'], [\\'_setCustomVar\\', 1, \\'site\\', \\'frontpage\\', 3], [\\'_setCustomVar\\', 2, \\'srpath\\', \\'frontpage-GET_listing\\', 3], [\\'_setCustomVar\\', 3, \\'usertype\\', user_type, 2], [\\'_setCustomVar\\', 4, \\'uitype\\', \\'web\\', 3], [\\'_setCustomVar\\', 5, \\'style_override\\', \\'\\', 2], [\\'_setSampleRate\\', \\'1\\'], [\\'_trackPageview\\'] ); (function() { var ga = document.createElement(\\'script\\'); ga.type = \\'text/javascript\\'; ga.async = true; ga.src = (\\'https:\\' == document.location.protocol ? \\'https://ssl\\' : \\'http://www\\') + \\'.google-analytics.com/ga.js\\'; var s = document.getElementsByTagName(\\'script\\')[0]; s.parentNode.insertBefore(ga, s); })();(function(i,s,o,g,r,a,m){i[\\'GoogleAnalyticsObject\\']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\\'script\\',\\'//www.google-analytics.com/analytics.js\\',\\'_ga\\'); window._ga(\\'create\\', \\'UA-12131688-9\\', { \\'name\\': \\'goldTracker\\', \\'cookieDomain\\': \\'reddit.com\\', \\'1\\': \\'frontpage\\', \\'2\\': \\'frontpage-GET_listing\\', \\'3\\': window.user_type, \\'4\\': \\'web\\', \\'sampleRate\\': 100 }); if (window.is_gold_page) { window._ga(\\'goldTracker.send\\', \\'pageview\\'); }document.querySelector(\\'#block-homepage\\').style.display = \\'block\\';var frame = document.createElement(\\'iframe\\'); frame.style.display = \\'none\\'; frame.referrer = \\'no-referrer\\'; frame.id = \\'gtm-jail\\'; frame.name = JSON.stringify({ subreddit: r.config.post_site, origin: location.origin, url: location.href, userMatching: r.config.feature_ads_user_matching, userId: r.config.user_id, advertiserCategory: r.config.advertiser_category, adsStatus: r.config.whitelist_status, }); frame.src = \\'//\\' + \"www.redditmedia.com\" + \\'/gtm/jail?cb=\\' + \"8CqR7FcToPI\"; document.body.appendChild(frame);var mf = document.createElement(\\'script\\'); mf.type = \\'text/javascript\\'; mf.async = true; mf.src = \"//www.redditstatic.com/moat/moatframe.js\"; var s = document.getElementsByTagName(\\'script\\')[0]; s.parentNode.insertBefore(mf, s);close this window<!-- Login form function --><div id=\"desktop-onboarding-browse\" class=\"c-step-sign-up\"><div class=\"desktop-onboarding-step desktop-onboarding-step_sign-up\"><div class=\"desktop-onboarding__col desktop-onboarding__col_sign-up_form\"><div class=\"reddit-logo\"><img width=\\'200px\\' src=\"//www.redditstatic.com/logo.svg\" /></div><h2 class=\"desktop-onboarding__title\">Sign up to get your own personalized Reddit experience!</h2><p class=\"desktop-onboarding__description\">By having a Reddit account, you can subscribe, vote, and comment on all your favorite Reddit content. Sign up in just seconds.</p><div class=\"desktop-onboarding-sign-up__form-container c-is-create\"><div class=\"desktop-onboarding-sign-up__form desktop-onboarding-sign-up__form_create\"><h3 class=\"desktop-onboarding-sign-up__form-title\">Create Account</h3><form class=\"sign-up-form\" id=\"desktop-onboarding-sign-up-form\" autocomplete=\"off\"><div class=\"c-form-group \"><label for=\"email\" class=\"screenreader-only\">email:</label><input name=\"email\" id=\"desktop-onboarding-email\" class=\"c-form-control\" type=\"text\" autofocus placeholder=\"email address\" data-validate-url=\"/api/check_email.json\" data-validate-on=\"keyup change blur\" /><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><button type=\"submit\" class=\"c-btn c-btn-primary desktop-onboarding__next-button\">Next</button><p class=\"desktop-onboarding-sign-up__form-note\"><span>Already have an account?</span><a href=\".\" class=\"desktop-onboarding-sign-up__form-toggler\" data-form=\"login\">Log In</a><a href=\"javascript: void 0;\" class=\"skip-for-now\">Skip for now</a></p></form></div><div class=\"desktop-onboarding-sign-up__form desktop-onboarding-sign-up__form_login\"><h3 class=\"desktop-onboarding-sign-up__form-title\">Log In</h3><form id=\"login-form\" method=\"post\" action=\"https://www.reddit.com/post/login\" class=\"form-v2 onboarding-login\"><input type=\"hidden\" name=\"op\" value=\"login\"><div class=\"c-form-group \"><label for=\"user_login\" class=\"screenreader-only\">username</label><input value=\"\" name=\"user\" id=\"user_login\" autofocus class=\"c-form-control\" type=\"text\" maxlength=\"20\" tabindex=\"3\" placeholder=\"username\" ><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><div class=\"c-form-group \"><label for=\"passwd_login\" class=\"screenreader-only\">password</label><input id=\"passwd_login\" class=\"c-form-control\" name=\"passwd\" type=\"password\" tabindex=\"3\" placeholder=\"password\" ><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><div class=\"desktop-onboarding-sign-up__form-note\"><span>Don\\'t have an account?</span><a href=\".\" class=\"desktop-onboarding-sign-up__form-toggler\" data-form=\"create\">Sign up</a>&nbsp|<a href=\"/password\">Reset password</a></div><input type=\"hidden\" value=\"yes\" name=\"rem\"/><div class=\"spacer\"><div class=\"c-form-group g-recaptcha\" data-sitekey=\"6LeTnxkTAAAAAN9QEuDZRpn90WwKk_R1TRW_g-JC\"></div><span class=\"error BAD_CAPTCHA field-captcha\" style=\"display:none\"></span></div><div class=\"c-clearfix c-submit-group\"><span class=\"c-form-throbber\"></span><button type=\"submit\" class=\"c-btn c-btn-primary c-pull-right\" tabindex=\"3\">log in</button></div><div><div class=\"c-alert c-alert-danger\"></div><span class=\"status\"></span></div></form></div></div><footer>By signing up, you agree to our&#32;<a href=\"https://www.reddit.com/help/useragreement/\" >Terms</a>&#32;and that you have read our&#32;<a href=\"https://www.reddit.com/help/privacypolicy/\" >Privacy Policy</a>&#32;and&#32;<a href=\"https://www.reddit.com/help/contentpolicy/\" >Content Policy</a>.</footer></div><div class=\"desktop-onboarding__col desktop-onboarding__col_sign-up_image\"></div></div><div class=\"desktop-onboarding-step desktop-onboarding-step_subreddit-picker\"><div class=\"subreddit-picker-header\"><h2 class=\"desktop-onboarding__title\">Find the good stuff</h2><p class=\"desktop-onboarding__description\">Reddit is filled with interest based communities, offering something for everyone. Check out some communities and we recommend you subscribe to at least 5.</p></div><div class=\"subreddit-picker\"><ul class=\"subreddit-picker__categories\"></ul><ul class=\"subreddit-picker__subreddits\"></ul><div class=\"subreddit-picker__fail\"><span>Something went wrong.</span><a href=\".\">Try Again?</a></div><div class=\"subreddit-picker__category-fail\"><span>Something went wrong.</span><a href=\".\">Try Again?</a></div></div><footer><div class=\"subreddit-picker-progress\"><div class=\"subreddit-picker-progress__track\"><div class=\"subreddit-picker-progress__bar\"></div></div><span class=\"subreddit-picker-progress__num\">0</span><span>/</span><span class=\"subreddit-picker-progress__denom\">5</span><span>&nbsp;<span class=\"subreddit-subscription-count\">recommended subscriptions</span></span></div><span class=\"desktop-onboarding__step-number\">Step 2 of 3</span><div class=\"desktop-onboarding__buttons\"><button class=\"c-btn desktop-onboarding__back-button\">Back</button><button class=\"c-btn c-btn-primary desktop-onboarding__next-button\">Next</button></div></footer></div><div class=\"desktop-onboarding-step desktop-onboarding-step_username\"><div class=\"desktop-onboarding__col desktop-onboarding__col_username_form\"><h2 class=\"desktop-onboarding__title\">Choose your username</h2><p class=\"desktop-onboarding__description\">Your username is how other community members will see you. This name will be used to credit you for things you share on Reddit. What should we call you?</p><div class=desktop-onboarding-username-form><form id=\"register-form\" method=\"post\" action=\"https://www.reddit.com/post/reg\" autocomplete=\"off\" class=\"form-v2 onboarding-login\"><input type=\"hidden\" name=\"op\" value=\"reg\"><input type=\"hidden\" id=\"desktop-onboarding-register-email\" name=\"email\" value=\"\"><input type=\"hidden\" id=\"desktop-onboarding-subreddits\" name=\"sr\" value=\"\"><div class=\"c-form-group \"><label class=\"desktop-onboarding-sign-up__form-title\" for=\"user_reg\">Choose username</label><input value=\"\" name=\"user\" id=\"user_reg\" autofocus class=\"c-form-control\" type=\"text\" maxlength=\"20\" tabindex=\"2\" placeholder=\"username\" data-validate-url=\"/api/check_username.json\" data-validate-min=\"3\" autocomplete=\"new-username\" ><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><div class=\"c-form-group \"><label for=\"passwd_reg\" class=\"desktop-onboarding-sign-up__form-title\">Set password</label><input id=\"passwd_reg\" class=\"c-form-control\" name=\"passwd\" type=\"password\" tabindex=\"2\" placeholder=\"password\" data-validate-url=\\'/api/check_password.json\\' autocomplete=\\'new-password\\'><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><input type=\"hidden\" name=\"passwd2\" id=\"passwd2_reg\" class=\"c-form-control\"><input type=\"hidden\" value=\"yes\" name=\"rem\"/><div class=\"spacer\"><div class=\"c-form-group g-recaptcha\" data-sitekey=\"6LeTnxkTAAAAAN9QEuDZRpn90WwKk_R1TRW_g-JC\"></div><span class=\"error BAD_CAPTCHA field-captcha\" style=\"display:none\"></span></div><div><div class=\"c-alert c-alert-danger\"></div><span class=\"status\"></span><span class=\"error RATELIMIT field-ratelimit\" style=\"display:none\"></span><span class=\"error RATELIMIT field-vdelay\" style=\"display:none\"></span></div></form></div></div><div class=\"desktop-onboarding__col desktop-onboarding__col_username_picker\"><div class=\"username-generator\"><p class=\"desktop-onboarding__description\">Having a hard time picking a name?<br />Here are some available suggestions.</p><div class=\"username-generator__suggestions\"></div><a href=\"javascript: void 0;\" class=\"username-generator__refresh-button\">Refresh suggestions</a></div><footer><span class=\"desktop-onboarding__step-number\">Step 3 of 3</span><div class=\"desktop-onboarding__buttons\"><button class=\"c-btn desktop-onboarding__back-button\">Back</button><button class=\"c-btn c-btn-primary desktop-onboarding__next-button\">Submit</button></div></footer></div></div></div>jump to contentmy subredditsedit subscriptionspopular-all-random-users\\xa0|\\xa0AskReddit-worldnews-videos-funny-todayilearned-pics-gaming-movies-news-gifs-mildlyinteresting-aww-Showerthoughts-television-Jokes-science-OldSchoolCool-sports-IAmA-Documentaries-TwoXChromosomes-explainlikeimfive-personalfinance-books-tifu-Futurology-dataisbeautiful-WritingPrompts-nottheonion-food-Music-photoshopbattles-EarthPorn-philosophy-Art-nosleep-GetMotivated-askscience-LifeProTips-space-UpliftingNews-DIY-history-gadgets-creepy-listentothis-blog-announcements-InternetIsBeautifulmore »reddit.com\\xa0hotnewrisingcontroversialtopgildedwikiWant to join? Log in or sign up in seconds.|Englishuse the following search parameters to narrow your results:subreddit:subredditfind submissions in \"subreddit\"author:usernamefind submissions by \"username\"site:example.comfind submissions from \"example.com\"url:textsearch for \"text\" in urlselftext:textsearch for \"text\" in self post contentsself:yes (or self:no)include (or exclude) self postsnsfw:yes (or nsfw:no)include (or exclude) results marked as NSFWe.g. subreddit:aww site:imgur.com dogsee the search faq for details.advanced search: by author, subreddit...remember mereset passwordloginr.hooks.get(\\'reddit\\').register(function() { window.googletag = window.googletag || {}; googletag.cmd = googletag.cmd || []; window.pbjs = window.pbjs || {}; pbjs.que = pbjs.que || []; var adblock = r.utils.getAdblockLevel(); var frameId = \"ad_2\"; var sizes = [[300, 250], [300, 600]]; var keywords = [\"k.military\", \"k.animated\", \"k.democracy\", \"s.frontpage\", \"k.party\", \"s.brandlift.holdout_6\", \"k.application\", \"s.loggedout\", \"s.sfw\", \"s.brandlift.holdout_9\"]; var properties = {\"placement\": \"atf\", \"pref_3rd_party_site_data_personalized_ads\": true, \"whitelist_status\": \"all_ads\", \"subreddit_screen\": false, \"pref_activity_relevant_ads\": true, \"percentage\": 11, \"iaa\": false, \"random_number\": 11, \"environment\": \"production\", \"pref_3rd_party_data_personalized_ads\": true, \"nsfw\": false, \"logged_in\": false, \"has_used_mobile_app\": false, \"full_url\": \"https://www.reddit.com/\"}; var slotPrefix = \"/32173961/desktop\"; var frame = document.getElementById(frameId); var ads = window.__adslots = window.__adslots || []; if (adblock === \\'whitelisted\\') { frame.className += \\' acceptable-ads\\'; } function isWithinLoadDistance(el) { var rect = el.getBoundingClientRect(); var html = document.documentElement; return (rect.top - (window.innerHeight || html.clientHeight))< 300; } function getPageType() { var $body = $(\\'body\\'); if ($body.hasClass(\\'comments-page\\')) { return \\'comments\\'; } else if ($body.hasClass(\\'profile-page\\')) { return \\'user\\' } else if ($body.hasClass(\\'listing-page\\')) { return \\'listing\\'; } } function getSlot(prefix, pageType) { var parts = [prefix]; if (pageType !== \\'user\\') { var listing = r.config.cur_listing; if (listing !== \\'frontpage\\') { listing = \\'r.\\' + listing; } parts.push(listing); } if (pageType) { parts.push(pageType); } return parts.join(\\'/\\'); } var adSlot; googletag.cmd.push(function() { var pageType = getPageType(); adSlot = googletag .defineSlot(getSlot(slotPrefix, pageType), sizes, frameId) .addService(googletag.pubads()); adSlot.setTargeting(\\'keywords\\', keywords); adSlot.setTargeting(\\'adblock\\', adblock); adSlot.setTargeting(\\'listing\\', pageType); Object.keys(properties).forEach(function(key) { adSlot.setTargeting(key, properties[key]); }); googletag.display(frameId); }); var requestAd = function() { if (window._usePrebid) { pbjs.que.push(function() { pbjs.setTargetingForGPTAsync(); googletag.pubads().refresh([adSlot]); }); } else { googletag.pubads().refresh([adSlot]); } }; ads.push({ slotID: frameId, sizes: sizes, callback: function() { googletag.cmd.push(function() { if (isWithinLoadDistance(frame)) { requestAd(); } else { var checkDistance = _.throttle(function() { if (isWithinLoadDistance(frame)) { requestAd(); window.removeEventListener(\\'scroll\\', checkDistance); } }, 100); window.addEventListener(\\'scroll\\', checkDistance); } }); }, }) });Submit a new linkSubmit a new text postdaily reddit gold goal57%help support redditreddit gold gives you extra features and helps keep our servers running. We believe the more reddit can be user-supported, the freer we will be to make reddit the best it can be.Buy gold for yourself to gain access to extra features and special benefits. A month of gold pays for  231.26 minutes of reddit server time!Give gold to thank exemplary people and encourage them to post more.This daily goal updates every 10 minutes and is reset at midnight Pacific Time  (9 hours, 33 minutes from now).Yesterday\\'s reddit gold goal83%r.hooks.get(\\'reddit\\').register(function() { window.googletag = window.googletag || {}; googletag.cmd = googletag.cmd || []; window.pbjs = window.pbjs || {}; pbjs.que = pbjs.que || []; var adblock = r.utils.getAdblockLevel(); var frameId = \"ad_6\"; var sizes = [[300, 250]]; var keywords = [\"k.military\", \"k.animated\", \"k.democracy\", \"s.frontpage\", \"k.application\", \"s.brandlift.holdout_6\", \"k.party\", \"s.loggedout\", \"s.sfw\", \"s.brandlift.holdout_9\"]; var properties = {\"placement\": \"btf\", \"pref_3rd_party_site_data_personalized_ads\": true, \"whitelist_status\": \"all_ads\", \"subreddit_screen\": false, \"pref_activity_relevant_ads\": true, \"percentage\": 22, \"iaa\": false, \"random_number\": 22, \"environment\": \"production\", \"pref_3rd_party_data_personalized_ads\": true, \"nsfw\": false, \"logged_in\": false, \"has_used_mobile_app\": false, \"full_url\": \"https://www.reddit.com/\"}; var slotPrefix = \"/32173961/desktop\"; var frame = document.getElementById(frameId); var ads = window.__adslots = window.__adslots || []; if (adblock === \\'whitelisted\\') { frame.className += \\' acceptable-ads\\'; } function isWithinLoadDistance(el) { var rect = el.getBoundingClientRect(); var html = document.documentElement; return (rect.top - (window.innerHeight || html.clientHeight))< 300; } function getPageType() { var $body = $(\\'body\\'); if ($body.hasClass(\\'comments-page\\')) { return \\'comments\\'; } else if ($body.hasClass(\\'profile-page\\')) { return \\'user\\' } else if ($body.hasClass(\\'listing-page\\')) { return \\'listing\\'; } } function getSlot(prefix, pageType) { var parts = [prefix]; if (pageType !== \\'user\\') { var listing = r.config.cur_listing; if (listing !== \\'frontpage\\') { listing = \\'r.\\' + listing; } parts.push(listing); } if (pageType) { parts.push(pageType); } return parts.join(\\'/\\'); } var adSlot; googletag.cmd.push(function() { var pageType = getPageType(); adSlot = googletag .defineSlot(getSlot(slotPrefix, pageType), sizes, frameId) .addService(googletag.pubads()); adSlot.setTargeting(\\'keywords\\', keywords); adSlot.setTargeting(\\'adblock\\', adblock); adSlot.setTargeting(\\'listing\\', pageType); Object.keys(properties).forEach(function(key) { adSlot.setTargeting(key, properties[key]); }); googletag.display(frameId); }); var requestAd = function() { if (window._usePrebid) { pbjs.que.push(function() { pbjs.setTargetingForGPTAsync(); googletag.pubads().refresh([adSlot]); }); } else { googletag.pubads().refresh([adSlot]); } }; ads.push({ slotID: frameId, sizes: sizes, callback: function() { googletag.cmd.push(function() { if (isWithinLoadDistance(frame)) { requestAd(); } else { var checkDistance = _.throttle(function() { if (isWithinLoadDistance(frame)) { requestAd(); window.removeEventListener(\\'scroll\\', checkDistance); } }, 100); window.addEventListener(\\'scroll\\', checkDistance); } }); }, }) });Welcome to Reddit,the front page of the internet.Become a Redditorand subscribe to one of thousands of communities.×popular in: United StatesEverywhereArgentinaAustraliaBulgariaCanadaChileColombiaCroatiaCzech RepublicFinlandGreeceHungaryIcelandIndiaIrelandJapanMalaysiaMexicoNew ZealandPhilippinesPolandPortugalPuerto RicoRomaniaSerbiaSingaporeSwedenTaiwanThailandTurkeyUnited Kingdomselect state: MassachusettsAll StatesAlaskaAlabamaArkansasArizonaCaliforniaColoradoConnecticutDistrict of ColumbiaDelawareFloridaGeorgiaHawaiiIowaIdahoIllinoisIndianaKansasKentuckyLouisianaMarylandMaineMichiganMinnesotaMissouriMississippiMontanaNorth CarolinaNorth DakotaNebraskaNew HampshireNew JerseyNew MexicoNevadaNew YorkOhioOklahomaOregonPennsylvaniaRhode IslandSouth CarolinaSouth DakotaTennesseeTexasUtahVirginiaVermontWashingtonWisconsinWest VirginiaWyomingr.spotlight.setup( [], 0.0, true, 1, \" reddit.com\", \"t3_7z7u1u,t3_7z79og,t3_7z7f8n,t3_7z6vrq,t3_7z71so,t3_7z6tt4,t3_7z6vxu,t3_7z6t9h,t3_7z73f2,t3_7z6kib\" )trending subredditsr/DesignPornr/sadlygokartsr/kaisamainsr/dontdeadopeninsider/smallbusiness40 commentsbody >.content .link .rank, .rank-spacer { width: 2.2ex } body >.content .link .midcol, .midcol-spacer { width: 7.1ex } .adsense-wrap { background-color: #eff7ff; font-size: 18px; padding-left: 9.3ex; padding-right: 5px; }130.5k30.5k30.5kThis is what democracy looks like. View from the Capitol in Tallahassee right now. (i.redd.it)submitted 3 hours ago by gangbangkang to r/pics4193 commentssharesavehidereportloading...215.5k15.5k15.5kTIL a party boat carrying sixty men and women once capsized in Texas after all the passangers rushed to one side as the boat passed a nude beach. (nbcnews.com)submitted 5 hours ago by Palana to r/todayilearned337 commentssharesavehidereport337.4k37.4k37.4k0:19Animated login avatar<form> (v.redd.it)submitted 3 hours ago by green__machine to r/web_design528 commentssharesavehidereportloading...425.0k25.0k25.0kPeter Wang, a 15-year-old member of the Junior ROTC who was killed as he tried to help fellow students escape a mass shooting in Parkland, posthumously admitted to the U.S. Military Academy. Wang and two other cadets, Martin Duque and Alaina Petty, both 14, were also awarded the Medal of Heroism. (npr.org)submitted 5 hours ago by modereddit to r/UpliftingNews743 commentssharesavehidereport540.7k40.7k40.7kLPT: Keep a separate master resume with ALL previous work experience. When sending out a resume for application, duplicate the file and remove anything that may be irrelevant to the position. You never know when some past experience might become relevant again, and you don’t want to forget about it.Careers & Work (self.LifeProTips)submitted 4 hours ago * by rlc327 to r/LifeProTips740 commentssharesavehidereportloading...647.4k47.4k47.4kFirst image ever taken of the Hydrogen Atom (i.imgur.com)submitted 5 hours ago by ballard09876 to r/woahdude1593 commentssharesavehidereportloading...7705706707Comprehensive look at just how good we\\'ve had it these past 17 years (OC) (i.redd.it)submitted 5 hours ago by thomaskvh676 to r/Patriots83 commentssharesavehidereportloading...838.2k38.2k38.2kNot a method actor (gfycat.com)submitted 5 hours ago by namraka to r/funny1912 commentssharesavehidereportloading...924.3k24.3k24.3kI\\'m gonna eat you little fishy (i.redd.it)submitted 4 hours ago by iduro to r/gifs676 commentssharesavehidereportloading...10975097519752Donna\\'s Contribution to Pawnee\\'s Time Capsule (i.imgur.com)submitted 6 hours ago by NightTrainDan to r/PandR182 commentssharesavehidereportloading...1119.0k19.0k19.0kSeizing an opportunity (i.imgur.com)submitted 5 hours ago by dickfromaccounting to r/MadeMeSmile377 commentssharesavehidereportloading...12110k110k110kOn the left: Scene from the first season of Stranger Things, set in 1983. On the right: Me, wearing the exact same shirt in 1983. (i.redd.it)submitted 6 hours ago by gaia88 to r/pics1872 commentssharesavehidereportloading...1310.4k10.4k10.4kDog Thinks<INTELLIGENCE> (i.imgur.com)submitted 6 hours ago by gugulo to r/likeus76 commentssharesavehidereportloading...1415.1k15.1k15.1kAt the end of Ferris Bueller’s Day Off, he appears to Deus Ex Machina a baseball to throw at his stereo he left on in order to save himself from being caught. Ferris actually caught that baseball at the Cubs game much earlier in the movie. (i.imgur.com)submitted 7 hours ago by Theogre84 to r/MovieDetails522 commentssharesavehidereportloading...1517.4k17.4k17.4kTrucker forgot he was driving a tractor trailer this morning while going through the bridge toll. (i.redd.it)submitted 6 hours ago by millhouse_kinda_guy to r/Wellthatsucks605 commentssharesavehidereportloading...16477147724773The Movie \"Cloudy with a Chance of Meatballs\" title was translated in Israel to \"It\\'s Raining Falafel\". (satofficial.com)submitted 4 hours ago by Pro_gra_mer to r/movies161 commentssharesavehidereport1735.6k35.6k35.6kElon Musk on Twitter: High altitude wind shear data shows a probable 2% load exceedance. Small, but better to be paranoid. Postponing launch to tomorrow, assuming winds are better then. (twitter.com)submitted 8 hours ago by jebotionmater to r/space1275 commentssharesavehidereport1814.5k14.5k14.5kMy First Attempt. (i.imgur.com)submitted 5 hours ago by myturn19 to r/tiltshift131 commentssharesavehidereportloading...1950.2k50.2k50.2kTank Puppy sees snow for the firs time at the Toronto Zoo. (gfycat.com)submitted 8 hours ago by PM_ME_STEAM_K3YS to r/aww690 commentssharesavehidereportloading...20697669776978Smooth Move On The Skateboardr/all (i.imgur.com)submitted 3 hours ago by yannireddit123 to r/BeAmazed168 commentssharesavehidereportloading...2124.3k24.3k24.3kWe still like cute goats, right? (i.imgur.com)submitted 7 hours ago by Aesopss to r/Eyebleach175 commentssharesavehidereportloading...2238.3k38.3k38.3kPsBattle: Dirty Cat in a Rail Yard (i.imgur.com)submitted 7 hours ago by BuffaloVampireSlayer to r/photoshopbattles431 commentssharesavehidereportloading...2386.8k86.8k86.8kThis morning reflection from my front door (i.redd.it)submitted 8 hours ago by embracingfit to r/mildlyinteresting1527 commentssharesavehidereportloading...2415.4k15.4k15.4kWOW! (i.redd.it)submitted 7 hours ago by E-RaticArtist to r/facepalm292 commentssharesavehidereportloading...2515.2k15.2k15.2kWoke up to a white world, gonna enjoy it from my favorite cozy chair (i.redd.it)submitted 6 hours ago by sunformyplants to r/CozyPlaces335 commentssharesavehidereportloading...view more: next ›<div class=\"interstitial\"><img class=\"interstitial-image\" src=\"//www.redditstatic.com/interstitial-image-archived.png\" alt=\"archived\" height=\"150\" width=\"150\"><div class=\"interstitial-message md-container\"><div class=\"md\"><h3>This is an archived post. You won\\'t be able to vote or comment.</h3><p>Posts&#32;are&#32;automatically&#32;archived&#32;after&#32;6&#32;months.</p></div></div><div class=\"buttons\"><a href=\"/\" class=\"c-btn c-btn-primary\">Got It</a></div></div>aboutblogaboutadvertisecareershelpsite ruleshelp centerwikireddiquettemod guidelinescontact usapps & toolsReddit for iPhoneReddit for Androidmobile websitebuttons<3reddit goldredditgiftsUse of this site constitutes acceptance of our User Agreement and Privacy Policy. © 2018 reddit inc. All rights reserved.REDDIT and the ALIEN Logo are registered trademarks of reddit inc.var BETA_HOST = \\'beta.reddit.com\\'; if (location.host === BETA_HOST) { r.config.https_endpoint = \\'https://\\' + BETA_HOST; }<!-- Login form function --><div id=\"desktop-onboarding-browse\" class=\"c-step-sign-up\"><div class=\"desktop-onboarding-step desktop-onboarding-step_sign-up\"><div class=\"desktop-onboarding__col desktop-onboarding__col_sign-up_form\"><div class=\"reddit-logo\"><img width=\\'200px\\' src=\"//www.redditstatic.com/logo.svg\" /></div><h2 class=\"desktop-onboarding__title\">Sign up to get your own personalized Reddit experience!</h2><p class=\"desktop-onboarding__description\">By having a Reddit account, you can subscribe, vote, and comment on all your favorite Reddit content. Sign up in just seconds.</p><div class=\"desktop-onboarding-sign-up__form-container c-is-create\"><div class=\"desktop-onboarding-sign-up__form desktop-onboarding-sign-up__form_create\"><h3 class=\"desktop-onboarding-sign-up__form-title\">Create Account</h3><form class=\"sign-up-form\" id=\"desktop-onboarding-sign-up-form\" autocomplete=\"off\"><div class=\"c-form-group \"><label for=\"email\" class=\"screenreader-only\">email:</label><input name=\"email\" id=\"desktop-onboarding-email\" class=\"c-form-control\" type=\"text\" autofocus placeholder=\"email address\" data-validate-url=\"/api/check_email.json\" data-validate-on=\"keyup change blur\" /><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><button type=\"submit\" class=\"c-btn c-btn-primary desktop-onboarding__next-button\">Next</button><p class=\"desktop-onboarding-sign-up__form-note\"><span>Already have an account?</span><a href=\".\" class=\"desktop-onboarding-sign-up__form-toggler\" data-form=\"login\">Log In</a><a href=\"javascript: void 0;\" class=\"skip-for-now\">Skip for now</a></p></form></div><div class=\"desktop-onboarding-sign-up__form desktop-onboarding-sign-up__form_login\"><h3 class=\"desktop-onboarding-sign-up__form-title\">Log In</h3><form id=\"login-form\" method=\"post\" action=\"https://www.reddit.com/post/login\" class=\"form-v2 onboarding-login\"><input type=\"hidden\" name=\"op\" value=\"login\"><div class=\"c-form-group \"><label for=\"user_login\" class=\"screenreader-only\">username</label><input value=\"\" name=\"user\" id=\"user_login\" autofocus class=\"c-form-control\" type=\"text\" maxlength=\"20\" tabindex=\"3\" placeholder=\"username\" ><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><div class=\"c-form-group \"><label for=\"passwd_login\" class=\"screenreader-only\">password</label><input id=\"passwd_login\" class=\"c-form-control\" name=\"passwd\" type=\"password\" tabindex=\"3\" placeholder=\"password\" ><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><div class=\"desktop-onboarding-sign-up__form-note\"><span>Don\\'t have an account?</span><a href=\".\" class=\"desktop-onboarding-sign-up__form-toggler\" data-form=\"create\">Sign up</a>&nbsp|<a href=\"/password\">Reset password</a></div><input type=\"hidden\" value=\"yes\" name=\"rem\"/><div class=\"spacer\"><div class=\"c-form-group g-recaptcha\" data-sitekey=\"6LeTnxkTAAAAAN9QEuDZRpn90WwKk_R1TRW_g-JC\"></div><span class=\"error BAD_CAPTCHA field-captcha\" style=\"display:none\"></span></div><div class=\"c-clearfix c-submit-group\"><span class=\"c-form-throbber\"></span><button type=\"submit\" class=\"c-btn c-btn-primary c-pull-right\" tabindex=\"3\">log in</button></div><div><div class=\"c-alert c-alert-danger\"></div><span class=\"status\"></span></div></form></div></div><footer>By signing up, you agree to our&#32;<a href=\"https://www.reddit.com/help/useragreement/\" >Terms</a>&#32;and that you have read our&#32;<a href=\"https://www.reddit.com/help/privacypolicy/\" >Privacy Policy</a>&#32;and&#32;<a href=\"https://www.reddit.com/help/contentpolicy/\" >Content Policy</a>.</footer></div><div class=\"desktop-onboarding__col desktop-onboarding__col_sign-up_image\"></div></div><div class=\"desktop-onboarding-step desktop-onboarding-step_subreddit-picker\"><div class=\"subreddit-picker-header\"><h2 class=\"desktop-onboarding__title\">Find the good stuff</h2><p class=\"desktop-onboarding__description\">Reddit is filled with interest based communities, offering something for everyone. Check out some communities and we recommend you subscribe to at least 5.</p></div><div class=\"subreddit-picker\"><ul class=\"subreddit-picker__categories\"></ul><ul class=\"subreddit-picker__subreddits\"></ul><div class=\"subreddit-picker__fail\"><span>Something went wrong.</span><a href=\".\">Try Again?</a></div><div class=\"subreddit-picker__category-fail\"><span>Something went wrong.</span><a href=\".\">Try Again?</a></div></div><footer><div class=\"subreddit-picker-progress\"><div class=\"subreddit-picker-progress__track\"><div class=\"subreddit-picker-progress__bar\"></div></div><span class=\"subreddit-picker-progress__num\">0</span><span>/</span><span class=\"subreddit-picker-progress__denom\">5</span><span>&nbsp;<span class=\"subreddit-subscription-count\">recommended subscriptions</span></span></div><span class=\"desktop-onboarding__step-number\">Step 2 of 3</span><div class=\"desktop-onboarding__buttons\"><button class=\"c-btn desktop-onboarding__back-button\">Back</button><button class=\"c-btn c-btn-primary desktop-onboarding__next-button\">Next</button></div></footer></div><div class=\"desktop-onboarding-step desktop-onboarding-step_username\"><div class=\"desktop-onboarding__col desktop-onboarding__col_username_form\"><h2 class=\"desktop-onboarding__title\">Choose your username</h2><p class=\"desktop-onboarding__description\">Your username is how other community members will see you. This name will be used to credit you for things you share on Reddit. What should we call you?</p><div class=desktop-onboarding-username-form><form id=\"register-form\" method=\"post\" action=\"https://www.reddit.com/post/reg\" autocomplete=\"off\" class=\"form-v2 onboarding-login\"><input type=\"hidden\" name=\"op\" value=\"reg\"><input type=\"hidden\" id=\"desktop-onboarding-register-email\" name=\"email\" value=\"\"><input type=\"hidden\" id=\"desktop-onboarding-subreddits\" name=\"sr\" value=\"\"><div class=\"c-form-group \"><label class=\"desktop-onboarding-sign-up__form-title\" for=\"user_reg\">Choose username</label><input value=\"\" name=\"user\" id=\"user_reg\" autofocus class=\"c-form-control\" type=\"text\" maxlength=\"20\" tabindex=\"2\" placeholder=\"username\" data-validate-url=\"/api/check_username.json\" data-validate-min=\"3\" autocomplete=\"new-username\" ><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><div class=\"c-form-group \"><label for=\"passwd_reg\" class=\"desktop-onboarding-sign-up__form-title\">Set password</label><input id=\"passwd_reg\" class=\"c-form-control\" name=\"passwd\" type=\"password\" tabindex=\"2\" placeholder=\"password\" data-validate-url=\\'/api/check_password.json\\' autocomplete=\\'new-password\\'><div class=\"c-form-control-feedback-wrapper \"><span class=\"c-form-control-feedback c-form-control-feedback-throbber\"></span><span class=\"c-form-control-feedback c-form-control-feedback-error\" title=\"\"></span><span class=\"c-form-control-feedback c-form-control-feedback-success\"></span></div></div><input type=\"hidden\" name=\"passwd2\" id=\"passwd2_reg\" class=\"c-form-control\"><input type=\"hidden\" value=\"yes\" name=\"rem\"/><div class=\"spacer\"><div class=\"c-form-group g-recaptcha\" data-sitekey=\"6LeTnxkTAAAAAN9QEuDZRpn90WwKk_R1TRW_g-JC\"></div><span class=\"error BAD_CAPTCHA field-captcha\" style=\"display:none\"></span></div><div><div class=\"c-alert c-alert-danger\"></div><span class=\"status\"></span><span class=\"error RATELIMIT field-ratelimit\" style=\"display:none\"></span><span class=\"error RATELIMIT field-vdelay\" style=\"display:none\"></span></div></form></div></div><div class=\"desktop-onboarding__col desktop-onboarding__col_username_picker\"><div class=\"username-generator\"><p class=\"desktop-onboarding__description\">Having a hard time picking a name?<br />Here are some available suggestions.</p><div class=\"username-generator__suggestions\"></div><a href=\"javascript: void 0;\" class=\"username-generator__refresh-button\">Refresh suggestions</a></div><footer><span class=\"desktop-onboarding__step-number\">Step 3 of 3</span><div class=\"desktop-onboarding__buttons\"><button class=\"c-btn desktop-onboarding__back-button\">Back</button><button class=\"c-btn c-btn-primary desktop-onboarding__next-button\">Submit</button></div></footer></div></div></div><form action=\"https://www.reddit.com/post/unlogged_options\" method=\"post\" class=\"pretty-form short-text\"><input type=\"hidden\" name=\"uh\" value=\"\" /><table class=\"content preftable\"><tr><th>interface language</th><td class=\"prefright\"><select id=\"lang\" name=\"lang\"><option selected=\\'selected\\' value=\"en\">English [en]</option><option value=\"af\">Afrikaans [af] (*)</option><option value=\"ar\">العربية [ar] (*)</option><option value=\"be\">Беларуская мова [be] (*)</option><option value=\"bg\">български език [bg]</option><option value=\"bn-IN\">বাংলা [bn-IN] (*)</option><option value=\"bn-bd\">বাংলা [bn-bd] (*)</option><option value=\"bs\">Bosanski [bs] (*)</option><option value=\"ca\">català [ca]</option><option value=\"cs\">česky [cs]</option><option value=\"cy\">Cymraeg [cy] (*)</option><option value=\"da\">dansk [da]</option><option value=\"de\">Deutsch [de]</option><option value=\"el\">Ελληνικά [el]</option><option value=\"en-au\">English (Australia) [en-au]</option><option value=\"en-ca\">English (Canadian) [en-ca]</option><option value=\"en-gb\">English (Great Britain) [en-gb]</option><option value=\"en-us\">English [en-us]</option><option value=\"eo\">Esperanto [eo] (*)</option><option value=\"es\">español [es]</option><option value=\"es-ar\">español [es-ar]</option><option value=\"es-cl\">español [es-cl]</option><option value=\"es-mx\">Español [es-mx]</option><option value=\"et\">eesti keel [et] (*)</option><option value=\"eu\">Euskara [eu]</option><option value=\"fa\">فارسی [fa]</option><option value=\"fi\">suomi [fi]</option><option value=\"fil\">Filipino [fil] (*)</option><option value=\"fr\">français [fr]</option><option value=\"fr-ca\">Français [fr-ca]</option><option value=\"fy-NL\">Frysk [fy-NL] (*)</option><option value=\"ga-ie\">Gaeilge [ga-ie] (*)</option><option value=\"gd\">Gàidhlig [gd]</option><option value=\"gl\">Galego [gl] (*)</option><option value=\"he\">עברית [he] (*)</option><option value=\"hi\">मानक हिन्दी [hi] (*)</option><option value=\"hr\">hrvatski [hr]</option><option value=\"hu\">Magyar [hu]</option><option value=\"hy\">Հայերեն լեզու [hy]</option><option value=\"id\">Bahasa Indonesia [id] (*)</option><option value=\"is\">íslenska [is]</option><option value=\"it\">italiano (Italy) [it]</option><option value=\"ja\">日本語 [ja]</option><option value=\"kn_IN\">ಕನ್ನಡ [kn_IN]</option><option value=\"ko\">한국어 [ko]</option><option value=\"la\">Latin [la] (*)</option><option value=\"leet\">1337 [leet]</option><option value=\"lol\">LOL [lol]</option><option value=\"lt\">lietuvių kalba [lt] (*)</option><option value=\"lv\">latviešu valoda [lv]</option><option value=\"ms\">Bahasa Melayu [ms] (*)</option><option value=\"mt-MT\">Malti [mt-MT]</option><option value=\"nl\">Nederlands [nl]</option><option value=\"nn\">Nynorsk [nn]</option><option value=\"no\">Norsk [no]</option><option value=\"pir\">Arrrrrrrr! [pir] (*)</option><option value=\"pl\">polski [pl]</option><option value=\"pt\">português [pt] (*)</option><option value=\"pt-pt\">português [pt-pt]</option><option value=\"pt_BR\">português brasileiro [pt_BR]</option><option value=\"ro\">română [ro]</option><option value=\"ru\">русский [ru]</option><option value=\"sk\">slovenčina [sk]</option><option value=\"sl\">slovenščina [sl] (*)</option><option value=\"sr\">српски језик [sr]</option><option value=\"sr-la\">Srpski [sr-la]</option><option value=\"sv\">Svenska [sv]</option><option value=\"ta\">தமிழ் [ta]</option><option value=\"th\">ภาษาไทย [th]</option><option value=\"tr\">Türkçe [tr]</option><option value=\"uk\">українська мова [uk]</option><option value=\"vi\">Tiếng Việt [vi]</option><option value=\"zh\">中文 [zh]</option><option value=\"zh-cn\">简化字 [zh-cn]</option></select>&#32;<span class=\"details hover\">(*) incomplete &#32;<a href=\"https://www.reddit.com/r/i18n/wiki/getting_started\">volunteer to translate</a></span></td></tr><tr><td><input type=\"submit\" class=\"btn\" value=\"save options\"/></td></tr></table></form>π\\xa0Rendered by PID 25766 on  app-185  at 2018-02-21 22:26:13.059790+00:00 running b222c1d country code: US.(function() { var ads = window.__adslots = window.__adslots || []; window.googletag = window.googletag || {}; googletag.cmd = googletag.cmd || []; function indexGoogleTagSlots(googSlots) { return googSlots.reduce(function(o, slot) { var slotID = slot.getSlotElementId(); o[slotID] = slot; return o; }, {}); } var gads = document.createElement(\\'script\\'); gads.async = true; gads.type = \\'text/javascript\\'; var useSSL = \\'https:\\' == document.location.protocol; gads.src = (useSSL ? \\'https:\\' : \\'http:\\') + \\'//www.googletagservices.com/tag/js/gpt.js\\'; var node = document.getElementsByTagName(\\'script\\')[0]; node.parentNode.insertBefore(gads, node); googletag.cmd.push(function() { googletag.pubads().disableInitialLoad(); googletag.pubads().setSafeFrameConfig({ allowOverlayExpansion: false, allowPushExpansion: false, sandbox: !(r.utils.testAcceptableAds() && /firefox/i.test(navigator.userAgent)), }); googletag.enableServices(); }); var percentage = 0.05; var usePrebid = window._usePrebid = Math.random()<= percentage || /.*prebid=1.*/.test(location.search || \\'\\'); if (usePrebid) { /* prebid */ window.pbjs = window.pbjs || {}; pbjs.que = pbjs.que || []; pbjs.que.push(function() { pbjs.setConfig({ priceGranularity: { buckets: [{ min: 0, max: 3, increment: 0.01, }, { min: 3, max: 8, increment: 0.05, }, { min: 8, max: 20, increment: 0.5, }, { min: 20, max: 35, increment: 1, }], }, }); }); var pb = document.createElement(\\'script\\'); pb.type = \\'text/javascript\\'; pb.async = true; pb.src = \"//www.redditstatic.com/js/prebid.js\"; var s = document.getElementsByTagName(\\'script\\')[0]; s.parentNode.insertBefore(pb, s); } else { /* amazon a9 ads */ !function(a9,a,p,s,t,A,g){if(a[a9])return;function q(c,r){a[a9]._Q.push([c,r])}a[a9]={init:function(){q(\\'i\\',arguments)},fetchBids:function(){q(\\'f\\',arguments)},_Q:[]};A=p.createElement(s);A.async=!0;A.src=t;g=p.getElementsByTagName(s)[0];g.parentNode.insertBefore(A,g)}(\\'apstag\\',window,document,\\'script\\',\\'//c.amazon-adsystem.com/aax2/apstag.js\\'); } r.hooks.get(\\'reddit\\').register(function() { var category = \"\"; if (!usePrebid) { apstag.init({ pubID: r.utils.testAcceptableAds() ? \\'3570\\' : \\'3379\\', adServer: \\'googletag\\', bidTimeout: 2e3, params: { position: \\'sidebar\\', section: category, sis_sitesection: [\\'reddit.com\\', category].filter(function(x) { return x; }).join(\\':\\'), subreddit: r.config.post_site, }, }); } googletag.cmd.push(function() { var adSlots = googletag.pubads().getSlots(); var headerBidCallback = function() { var callbacks = _.pluck(ads, \\'callback\\'); _.invoke(callbacks, \\'call\\'); }; if (usePrebid) { var bidsBackHandler = function() { if (pbjs.adserverRequestSent) return; pbjs.adserverRequestSent = true; headerBidCallback(); }; pbjs.que.push(function() { pbjs.addAdUnits(ads.map(function(ad) { return { code: ad.slotID, sizes: ad.sizes, bids: [{ bidder: \\'appnexus\\', params: { placementId: \\'11905719\\', }, }], }; })); pbjs.requestBids({ bidsBackHandler: bidsBackHandler, }); }); setTimeout(bidsBackHandler, 700); } else { apstag.fetchBids({ slots: _.map(ads, function(ad) { return _.pick(ad, [\\'slotID\\', \\'sizes\\']); }), timeout: 2e3, }, function(bids) { googletag.cmd.push(function() { var slotsById = indexGoogleTagSlots(adSlots); bids.forEach(function(bid) { var slot = slotsById[bid.slotID]; if (slot) { apstag.targetingKeys().forEach(function(key) { slot.setTargeting(key, bid[key]) }); } }); }); headerBidCallback(); }); } }); }); })();'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The thread title is within an `<a>` tag with the attribute `data-event-action=\"title\"`.\n",
    "- The time since the thread was created is within a `<time>` tag with attribute `class=\"live-timestamp\"`.\n",
    "- The subreddit is within an `<a>` tag with the attribute `class=\"subreddit hover may-blank\"`.\n",
    "- The number of comments is within an `<a>` tag with the attribute data-event-action=\"comments\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4193</td>\n",
       "      <td>pics</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>This is what democracy looks like. View from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>TIL a party boat carrying sixty men and women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528</td>\n",
       "      <td>web_design</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>Animated login avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>743</td>\n",
       "      <td>UpliftingNews</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Peter Wang, a 15-year-old member of the Junior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>740</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>LPT: Keep a separate master resume with ALL pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1593</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>First image ever taken of the Hydrogen Atom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Comprehensive look at just how good we've had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1912</td>\n",
       "      <td>funny</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Not a method actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>676</td>\n",
       "      <td>gifs</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>I'm gonna eat you little fishy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>182</td>\n",
       "      <td>PandR</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Donna's Contribution to Pawnee's Time Capsule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>377</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Seizing an opportunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1872</td>\n",
       "      <td>pics</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>On the left: Scene from the first season of St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>76</td>\n",
       "      <td>likeus</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Dog Thinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>522</td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>At the end of Ferris Bueller’s Day Off, he app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>605</td>\n",
       "      <td>Wellthatsucks</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Trucker forgot he was driving a tractor traile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>161</td>\n",
       "      <td>movies</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>The Movie \"Cloudy with a Chance of Meatballs\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1275</td>\n",
       "      <td>space</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Elon Musk on Twitter: High altitude wind shear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>131</td>\n",
       "      <td>tiltshift</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>My First Attempt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>690</td>\n",
       "      <td>aww</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Tank Puppy sees snow for the firs time at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>168</td>\n",
       "      <td>BeAmazed</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>Smooth Move On The Skateboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>175</td>\n",
       "      <td>Eyebleach</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>We still like cute goats, right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>431</td>\n",
       "      <td>photoshopbattles</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>PsBattle: Dirty Cat in a Rail Yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1527</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>This morning reflection from my front door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>292</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>WOW!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>335</td>\n",
       "      <td>CozyPlaces</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Woke up to a white world, gonna enjoy it from ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    comments          subreddit         time  \\\n",
       "0       4193               pics  3 hours ago   \n",
       "1        337      todayilearned  5 hours ago   \n",
       "2        528         web_design  3 hours ago   \n",
       "3        743      UpliftingNews  5 hours ago   \n",
       "4        740        LifeProTips  4 hours ago   \n",
       "5       1593           woahdude  5 hours ago   \n",
       "6         83           Patriots  5 hours ago   \n",
       "7       1912              funny  5 hours ago   \n",
       "8        676               gifs  4 hours ago   \n",
       "9        182              PandR  6 hours ago   \n",
       "10       377        MadeMeSmile  5 hours ago   \n",
       "11      1872               pics  6 hours ago   \n",
       "12        76             likeus  6 hours ago   \n",
       "13       522       MovieDetails  7 hours ago   \n",
       "14       605      Wellthatsucks  6 hours ago   \n",
       "15       161             movies  4 hours ago   \n",
       "16      1275              space  8 hours ago   \n",
       "17       131          tiltshift  5 hours ago   \n",
       "18       690                aww  8 hours ago   \n",
       "19       168           BeAmazed  3 hours ago   \n",
       "20       175          Eyebleach  7 hours ago   \n",
       "21       431   photoshopbattles  7 hours ago   \n",
       "22      1527  mildlyinteresting  8 hours ago   \n",
       "23       292           facepalm  7 hours ago   \n",
       "24       335         CozyPlaces  6 hours ago   \n",
       "\n",
       "                                                title  \n",
       "0   This is what democracy looks like. View from t...  \n",
       "1   TIL a party boat carrying sixty men and women ...  \n",
       "2                               Animated login avatar  \n",
       "3   Peter Wang, a 15-year-old member of the Junior...  \n",
       "4   LPT: Keep a separate master resume with ALL pr...  \n",
       "5         First image ever taken of the Hydrogen Atom  \n",
       "6   Comprehensive look at just how good we've had ...  \n",
       "7                                  Not a method actor  \n",
       "8                      I'm gonna eat you little fishy  \n",
       "9       Donna's Contribution to Pawnee's Time Capsule  \n",
       "10                             Seizing an opportunity  \n",
       "11  On the left: Scene from the first season of St...  \n",
       "12                                         Dog Thinks  \n",
       "13  At the end of Ferris Bueller’s Day Off, he app...  \n",
       "14  Trucker forgot he was driving a tractor traile...  \n",
       "15  The Movie \"Cloudy with a Chance of Meatballs\" ...  \n",
       "16  Elon Musk on Twitter: High altitude wind shear...  \n",
       "17                                  My First Attempt.  \n",
       "18  Tank Puppy sees snow for the firs time at the ...  \n",
       "19                      Smooth Move On The Skateboard  \n",
       "20                   We still like cute goats, right?  \n",
       "21                 PsBattle: Dirty Cat in a Rail Yard  \n",
       "22         This morning reflection from my front door  \n",
       "23                                               WOW!  \n",
       "24  Woke up to a white world, gonna enjoy it from ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting data from 1st page\n",
    "\n",
    "results_list = []\n",
    "all_td = soup.find_all('div', {'class':'top-matter'})\n",
    "for element in all_td:\n",
    "    result = {}\n",
    "    \n",
    "    title = element.find('a', {'data-event-action':'title'})\n",
    "    #title = element.find('a')\n",
    "    if title:\n",
    "        result['title'] = title.text\n",
    "    \n",
    "    subreddit = element.find('a', {'class':'subreddit hover may-blank'})\n",
    "    if subreddit:\n",
    "        result['subreddit'] = subreddit.text.strip()[2:]\n",
    "\n",
    "        \n",
    "    #time = element.find('p', {'class':'tagline'})\n",
    "    time = element.find('time', {'class':'live-timestamp'})\n",
    "    if time:\n",
    "        result['time'] = time.text\n",
    "        \n",
    "    #comments = element.find('li', {'class':'first'})\n",
    "    comments = element.find('a', {'data-event-action':'comments'})\n",
    "    if comments:\n",
    "        result['comments'] = int(comments.text.strip()[0:-9])\n",
    "    \n",
    "    results_list.append(result)\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(results_list)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract these items (one function for each): title, time, subreddit, and number of comments.¶\n",
    "Example\n",
    "```python\n",
    "def extract_title_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_title(result):\n",
    "    title = element.find('a', {'data-event-action':'title'})\n",
    "    if title:\n",
    "        return title.text\n",
    "\n",
    "def extract_subreddit(result):\n",
    "    subreddit = element.find('a', {'class':'subreddit hover may-blank'})\n",
    "    if subreddit:\n",
    "        return subreddit.text.strip()[2:]\n",
    "\n",
    "def extract_time(result):\n",
    "    time = element.find('time', {'class':'live-timestamp'})\n",
    "    if time:\n",
    "        return time.text\n",
    "\n",
    "def extract_comment(result):\n",
    "    comments = element.find('a', {'data-event-action':'comments'})\n",
    "    if comments:\n",
    "        return int(comments.text.strip()[0:-9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results.\n",
    "\n",
    "First, look at the source of a Reddit.com page: (https://www.reddit.com/).\n",
    "Try manually changing the page by clicking the 'next' button on the bottom. Look at how the url changes.\n",
    "\n",
    "After leaving the Reddit homepage, the URLs should look something like this:\n",
    "```\n",
    "https://www.reddit.com/?count=25&after=t3_787ptc\n",
    "```\n",
    "\n",
    "The URL here has two query parameters\n",
    "- count is the result number that the page starts with\n",
    "- after is the unique id of the last result on the _previous_ page\n",
    "\n",
    "In order to scrape lots of pages from Reddit, we'll have to change these parameters every time we make a new request so that we're not just scraping the same page over and over again. Incrementing the count by 25 every time will be easy, but the bizarre code after `after` is a bit trickier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off, let's look at a block of HTML from a Reddit page to see how we might solve this problem:\n",
    "```html\n",
    "<div class=\" thing id-t3_788tye odd gilded link \" data-author=\"LordSneaux\" data-author-fullname=\"t2_j3pty\" data-comments-count=\"1548\" data-context=\"listing\" data-domain=\"v.redd.it\" data-fullname=\"t3_788tye\" data-kind=\"video\" data-num-crossposts=\"0\" data-permalink=\"/r/funny/comments/788tye/not_all_heroes_wear_capes/\" data-rank=\"25\" data-score=\"51468\" data-subreddit=\"funny\" data-subreddit-fullname=\"t5_2qh33\" data-timestamp=\"1508775581000\" data-type=\"link\" data-url=\"https://v.redd.it/ush0rh2tultz\" data-whitelist-status=\"all_ads\" id=\"thing_t3_788tye\" onclick=\"click_thing(this)\">\n",
    "      <p class=\"parent\">\n",
    "      </p>\n",
    "      <span class=\"rank\">\n",
    "       25\n",
    "      </span>\n",
    "      <div class=\"midcol unvoted\">\n",
    "       <div aria-label=\"upvote\" class=\"arrow up login-required access-required\" data-event-action=\"upvote\" role=\"button\" tabindex=\"0\">\n",
    "       </div>\n",
    "       <div class=\"score dislikes\" title=\"53288\">\n",
    "        53.3k\n",
    "       </div>\n",
    "       <div class=\"score unvoted\" title=\"53289\">\n",
    "        53.3k\n",
    "       </div>\n",
    "       <div class=\"score likes\" title=\"53290\">\n",
    "        53.3k\n",
    "       </div>\n",
    "       <div aria-label=\"downvote\" class=\"arrow down login-required access-required\" data-event-action=\"downvote\" role=\"button\" tabindex=\"0\">\n",
    "       </div>\n",
    "      </div>\n",
    "```\n",
    "\n",
    "Notice that within the `div` tag there is an attribute called `id` and it is set to `\"thing_t3_788tye\"`. By finding the last ID on your scraped page, you can tell your _next_ request where to start (pass everything after \"thing_\").\n",
    "\n",
    "For more info on this, you can take a look at the [Reddit API docs](https://github.com/reddit/reddit/wiki/JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write one more function that finds the last `id` on the page, and stores it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3_7z7u1u\n"
     ]
    }
   ],
   "source": [
    "main_table = soup.find('div', {'id':'siteTable'})\n",
    "page = main_table.find_all ('div')\n",
    "\n",
    "\n",
    "for element in page: \n",
    "    idx = element['data-fullname']\n",
    "    print (idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Collect more information\n",
    "\n",
    "While we only require you to collect four features, there may be other info that you can find on the results page that might be useful. Feel free to write more functions so that you have more interesting and useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's put it all together.\n",
    "\n",
    "Use the functions you wrote above to parse out the 4 fields - title, time, subreddit, and number of comments. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>260</td>\n",
       "      <td>Shitty_Car_Mods</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>I thought I was having a stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173</td>\n",
       "      <td>DnD</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>So, my mom rolled a druid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>724</td>\n",
       "      <td>books</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Amazon confirm they will be adapting Iain M Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1058</td>\n",
       "      <td>science</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>How a person responds to a difficult life even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>274</td>\n",
       "      <td>IDontWorkHereLady</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Pour water on me, Lose your money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>Blep</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>My little dick faced blep machine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36</td>\n",
       "      <td>crappyoffbrands</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Everybody make way, Swoletrooper coming through!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>futurama</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>How I feel when I watch the Olympics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61</td>\n",
       "      <td>KenM</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Ken M on global warming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>359</td>\n",
       "      <td>pics</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Brave Iranian woman just before being arrested...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2183</td>\n",
       "      <td>television</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>Netflix is focusing more and more on TV shows ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>149</td>\n",
       "      <td>oddlysatisfying</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>The way this keyboard sinks right in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57</td>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Woodoo - Stop motion with wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1695</td>\n",
       "      <td>Whatcouldgowrong</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>Just going to shoot this fridge WCGW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26</td>\n",
       "      <td>calvinandhobbes</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>The simple things in life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>funny</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Barry it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>140</td>\n",
       "      <td>BlueMidterm2018</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Rep. Ryan Costello (R-PA6) says he would suppo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>902</td>\n",
       "      <td>WatchPeopleDieInside</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>Runner celebrates just a tad too early and los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>466</td>\n",
       "      <td>assholedesign</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>This shower gel bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>75</td>\n",
       "      <td>Awwducational</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>As a rule of thumb the foraging area around a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>189</td>\n",
       "      <td>reactiongifs</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>MRW two studies come out at roughly the same t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>202</td>\n",
       "      <td>blunderyears</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Me (in red) and my much more photogenic older ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>47</td>\n",
       "      <td>gamegrumps</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>I love Ninja sex party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "      <td>funny</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>What about brown ones ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>386</td>\n",
       "      <td>wholesomememes</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>Doggo graduates police academy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>173</td>\n",
       "      <td>DnD</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>So, my mom rolled a druid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>724</td>\n",
       "      <td>books</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Amazon confirm they will be adapting Iain M Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1058</td>\n",
       "      <td>science</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>How a person responds to a difficult life even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>274</td>\n",
       "      <td>IDontWorkHereLady</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Pour water on me, Lose your money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>43</td>\n",
       "      <td>Blep</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>My little dick faced blep machine.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>281</td>\n",
       "      <td>CampingandHiking</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>My cousin is suicidal and believed to be in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>18</td>\n",
       "      <td>sbubby</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>4 for one :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>25</td>\n",
       "      <td>submechanophobia</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Imagine falling off from a gust of wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>66</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>TIL Billy Graham bailed Martin Luther King out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>244</td>\n",
       "      <td>confession</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>My wife leaves me home alone with the dogs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>121</td>\n",
       "      <td>CrappyDesign</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>Babe, this negative space is amazing, let's ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>65</td>\n",
       "      <td>StoppedWorking</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>Legs.exe update has a bug in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>59</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>ELI5: Why do pictures of a computer screen loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>33</td>\n",
       "      <td>NotMyJob</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>Put out the cooking magazines, boss!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>16</td>\n",
       "      <td>tuckedinkitties</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Post Zoomies Wind down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>16</td>\n",
       "      <td>BikiniBottomTwitter</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>Happens to the best of us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>35</td>\n",
       "      <td>mildlyinfuriating</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>Discovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>27</td>\n",
       "      <td>Perfectfit</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>This new printer I bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>92</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>TIL the Great Lakes have at least 6,000 shipwr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>44</td>\n",
       "      <td>AbandonedPorn</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>The abandoned house in the pumpkin field [OC] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>48</td>\n",
       "      <td>memes</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>Its a woofer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>123</td>\n",
       "      <td>FortNiteBR</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Lv100 Season 3 Skin LEAKED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>445</td>\n",
       "      <td>news</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Levy County School District announced any stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>38</td>\n",
       "      <td>AnimalsBeingBros</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>The dog was on time out, and got sent to his c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>127</td>\n",
       "      <td>howto</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>How to clean, maintain, and season a cast iron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>223</td>\n",
       "      <td>vexillology</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>FIFA's solution to making flags with union Jac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>33</td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>I live in a European city where they have foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>3034</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>What's a joke that's so stupid it's funny?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>26</td>\n",
       "      <td>zelda</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Today Is Legend Of Zelda's 32nd Anniversary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>281</td>\n",
       "      <td>CampingandHiking</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>My cousin is suicidal and believed to be in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>18</td>\n",
       "      <td>sbubby</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>4 for one :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>25</td>\n",
       "      <td>submechanophobia</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Imagine falling off from a gust of wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>66</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>TIL Billy Graham bailed Martin Luther King out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>244</td>\n",
       "      <td>confession</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>My wife leaves me home alone with the dogs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>203</td>\n",
       "      <td>battlestations</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>New Apartment, New battlestation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     comments             subreddit          time  \\\n",
       "0         260       Shitty_Car_Mods   9 hours ago   \n",
       "1         173                   DnD   8 hours ago   \n",
       "2         724                 books   8 hours ago   \n",
       "3        1058               science  11 hours ago   \n",
       "4         274     IDontWorkHereLady   7 hours ago   \n",
       "5          43                  Blep   7 hours ago   \n",
       "6          36       crappyoffbrands   6 hours ago   \n",
       "7          17              futurama   5 hours ago   \n",
       "8          61                  KenM   7 hours ago   \n",
       "9         359                  pics   8 hours ago   \n",
       "10       2183            television  11 hours ago   \n",
       "11        149       oddlysatisfying   9 hours ago   \n",
       "12         57     interestingasfuck   8 hours ago   \n",
       "13       1695      Whatcouldgowrong  10 hours ago   \n",
       "14         26       calvinandhobbes   9 hours ago   \n",
       "15         40                 funny   5 hours ago   \n",
       "16        140       BlueMidterm2018   7 hours ago   \n",
       "17        902  WatchPeopleDieInside  11 hours ago   \n",
       "18        466         assholedesign  11 hours ago   \n",
       "19         75         Awwducational   6 hours ago   \n",
       "20        189          reactiongifs  12 hours ago   \n",
       "21        202          blunderyears   8 hours ago   \n",
       "22         47            gamegrumps   4 hours ago   \n",
       "23         61                 funny   5 hours ago   \n",
       "24        386        wholesomememes  12 hours ago   \n",
       "25        173                   DnD   8 hours ago   \n",
       "26        724                 books   8 hours ago   \n",
       "27       1058               science  11 hours ago   \n",
       "28        274     IDontWorkHereLady   7 hours ago   \n",
       "29         43                  Blep   7 hours ago   \n",
       "...       ...                   ...           ...   \n",
       "4970      281      CampingandHiking  14 hours ago   \n",
       "4971       18                sbubby   5 hours ago   \n",
       "4972       25      submechanophobia   4 hours ago   \n",
       "4973       66         todayilearned   2 hours ago   \n",
       "4974      244            confession   6 hours ago   \n",
       "4975      121          CrappyDesign  12 hours ago   \n",
       "4976       65        StoppedWorking  10 hours ago   \n",
       "4977       59     explainlikeimfive   2 hours ago   \n",
       "4978       33              NotMyJob  10 hours ago   \n",
       "4979       16       tuckedinkitties   7 hours ago   \n",
       "4980       16   BikiniBottomTwitter   9 hours ago   \n",
       "4981       35     mildlyinfuriating   2 hours ago   \n",
       "4982       27            Perfectfit   5 hours ago   \n",
       "4983       92         todayilearned   4 hours ago   \n",
       "4984       44         AbandonedPorn   6 hours ago   \n",
       "4985       48                 memes   9 hours ago   \n",
       "4986      123            FortNiteBR   6 hours ago   \n",
       "4987      445                  news   4 hours ago   \n",
       "4988       38      AnimalsBeingBros   8 hours ago   \n",
       "4989      127                 howto   6 hours ago   \n",
       "4990      223           vexillology  11 hours ago   \n",
       "4991       33         AskHistorians   6 hours ago   \n",
       "4992     3034             AskReddit  10 hours ago   \n",
       "4993       26                 zelda   4 hours ago   \n",
       "4994      281      CampingandHiking  14 hours ago   \n",
       "4995       18                sbubby   5 hours ago   \n",
       "4996       25      submechanophobia   4 hours ago   \n",
       "4997       66         todayilearned   2 hours ago   \n",
       "4998      244            confession   6 hours ago   \n",
       "4999      203        battlestations  10 hours ago   \n",
       "\n",
       "                                                  title  \n",
       "0                       I thought I was having a stroke  \n",
       "1                            So, my mom rolled a druid.  \n",
       "2     Amazon confirm they will be adapting Iain M Ba...  \n",
       "3     How a person responds to a difficult life even...  \n",
       "4                    Pour water on me, Lose your money.  \n",
       "5                    My little dick faced blep machine.  \n",
       "6      Everybody make way, Swoletrooper coming through!  \n",
       "7                  How I feel when I watch the Olympics  \n",
       "8                               Ken M on global warming  \n",
       "9     Brave Iranian woman just before being arrested...  \n",
       "10    Netflix is focusing more and more on TV shows ...  \n",
       "11                 The way this keyboard sinks right in  \n",
       "12                       Woodoo - Stop motion with wood  \n",
       "13                 Just going to shoot this fridge WCGW  \n",
       "14                           The simple things in life.  \n",
       "15                                             Barry it  \n",
       "16    Rep. Ryan Costello (R-PA6) says he would suppo...  \n",
       "17    Runner celebrates just a tad too early and los...  \n",
       "18                               This shower gel bottle  \n",
       "19    As a rule of thumb the foraging area around a ...  \n",
       "20    MRW two studies come out at roughly the same t...  \n",
       "21    Me (in red) and my much more photogenic older ...  \n",
       "22                               I love Ninja sex party  \n",
       "23                              What about brown ones ?  \n",
       "24                       Doggo graduates police academy  \n",
       "25                           So, my mom rolled a druid.  \n",
       "26    Amazon confirm they will be adapting Iain M Ba...  \n",
       "27    How a person responds to a difficult life even...  \n",
       "28                   Pour water on me, Lose your money.  \n",
       "29                   My little dick faced blep machine.  \n",
       "...                                                 ...  \n",
       "4970  My cousin is suicidal and believed to be in a ...  \n",
       "4971                                       4 for one :)  \n",
       "4972            Imagine falling off from a gust of wind  \n",
       "4973  TIL Billy Graham bailed Martin Luther King out...  \n",
       "4974        My wife leaves me home alone with the dogs.  \n",
       "4975  Babe, this negative space is amazing, let's ge...  \n",
       "4976                    Legs.exe update has a bug in it  \n",
       "4977  ELI5: Why do pictures of a computer screen loo...  \n",
       "4978               Put out the cooking magazines, boss!  \n",
       "4979                             Post Zoomies Wind down  \n",
       "4980                          Happens to the best of us  \n",
       "4981                                          Discovery  \n",
       "4982                          This new printer I bought  \n",
       "4983  TIL the Great Lakes have at least 6,000 shipwr...  \n",
       "4984  The abandoned house in the pumpkin field [OC] ...  \n",
       "4985                                       Its a woofer  \n",
       "4986                         Lv100 Season 3 Skin LEAKED  \n",
       "4987  Levy County School District announced any stud...  \n",
       "4988  The dog was on time out, and got sent to his c...  \n",
       "4989  How to clean, maintain, and season a cast iron...  \n",
       "4990  FIFA's solution to making flags with union Jac...  \n",
       "4991  I live in a European city where they have foun...  \n",
       "4992         What's a joke that's so stupid it's funny?  \n",
       "4993        Today Is Legend Of Zelda's 32nd Anniversary  \n",
       "4994  My cousin is suicidal and believed to be in a ...  \n",
       "4995                                       4 for one :)  \n",
       "4996            Imagine falling off from a gust of wind  \n",
       "4997  TIL Billy Graham bailed Martin Luther King out...  \n",
       "4998        My wife leaves me home alone with the dogs.  \n",
       "4999                   New Apartment, New battlestation  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting data from other pages\n",
    "\n",
    "url_template = \"http://www.reddit.com/?count={}&after={}\"\n",
    "max_results = 5000 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "\n",
    "results = []\n",
    "results_list = []\n",
    "\n",
    "for start in range(0, max_results, 25):\n",
    "    \n",
    "    headers = {\n",
    "    'User-Agent': 'Project3-ClaudiaGreco',\n",
    "    'From': 'claugreco@gmail.com'\n",
    "    }\n",
    "\n",
    "    url = url_template.format(start, idx)\n",
    "    #print ('URL: ', url)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    html = response.text\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    all_td = soup.find_all('div', {'class':'top-matter'})\n",
    "    for element in all_td:\n",
    "        result = {}\n",
    "    \n",
    "        title = element.find('a', {'data-event-action':'title'})\n",
    "        if title:\n",
    "            result['title'] = title.text\n",
    "    \n",
    "        subreddit = element.find('a', {'class':'subreddit hover may-blank'})\n",
    "        if subreddit:\n",
    "            result['subreddit'] = subreddit.text.strip()[2:]\n",
    "\n",
    "        time = element.find('time', {'class':'live-timestamp'})\n",
    "        if time:\n",
    "            result['time'] = time.text\n",
    "        \n",
    "        comments = element.find('a', {'data-event-action':'comments'})\n",
    "        if comments:\n",
    "            result['comments'] = comments.text.strip()[0:-9]\n",
    "\n",
    "        \n",
    "        results_list.append(result)\n",
    "\n",
    "        #Next page id\n",
    "    main_table = soup.find('div', {'id':'siteTable'})\n",
    "    page = main_table.find_all ('div')\n",
    "\n",
    "    for element in page: \n",
    "        idx = element['data-fullname']\n",
    "        if idx:\n",
    "            #print (idx)\n",
    "            break\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(results_list)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4193</td>\n",
       "      <td>pics</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>This is what democracy looks like. View from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>TIL a party boat carrying sixty men and women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>528</td>\n",
       "      <td>web_design</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>Animated login avatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>743</td>\n",
       "      <td>UpliftingNews</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Peter Wang, a 15-year-old member of the Junior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>740</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>LPT: Keep a separate master resume with ALL pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1593</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>First image ever taken of the Hydrogen Atom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83</td>\n",
       "      <td>Patriots</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Comprehensive look at just how good we've had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1912</td>\n",
       "      <td>funny</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Not a method actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>676</td>\n",
       "      <td>gifs</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>I'm gonna eat you little fishy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>182</td>\n",
       "      <td>PandR</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Donna's Contribution to Pawnee's Time Capsule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>377</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>Seizing an opportunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1872</td>\n",
       "      <td>pics</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>On the left: Scene from the first season of St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>76</td>\n",
       "      <td>likeus</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Dog Thinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>522</td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>At the end of Ferris Bueller’s Day Off, he app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>605</td>\n",
       "      <td>Wellthatsucks</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Trucker forgot he was driving a tractor traile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>161</td>\n",
       "      <td>movies</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>The Movie \"Cloudy with a Chance of Meatballs\" ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1275</td>\n",
       "      <td>space</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Elon Musk on Twitter: High altitude wind shear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>131</td>\n",
       "      <td>tiltshift</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>My First Attempt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>690</td>\n",
       "      <td>aww</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Tank Puppy sees snow for the firs time at the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>168</td>\n",
       "      <td>BeAmazed</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>Smooth Move On The Skateboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>175</td>\n",
       "      <td>Eyebleach</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>We still like cute goats, right?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>431</td>\n",
       "      <td>photoshopbattles</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>PsBattle: Dirty Cat in a Rail Yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1527</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>This morning reflection from my front door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>292</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>WOW!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>335</td>\n",
       "      <td>CozyPlaces</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Woke up to a white world, gonna enjoy it from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>260</td>\n",
       "      <td>Shitty_Car_Mods</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>I thought I was having a stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>173</td>\n",
       "      <td>DnD</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>So, my mom rolled a druid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>724</td>\n",
       "      <td>books</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>Amazon confirm they will be adapting Iain M Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1058</td>\n",
       "      <td>science</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>How a person responds to a difficult life even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>274</td>\n",
       "      <td>IDontWorkHereLady</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Pour water on me, Lose your money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>281</td>\n",
       "      <td>CampingandHiking</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>My cousin is suicidal and believed to be in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>18</td>\n",
       "      <td>sbubby</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>4 for one :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>25</td>\n",
       "      <td>submechanophobia</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Imagine falling off from a gust of wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>66</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>TIL Billy Graham bailed Martin Luther King out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>244</td>\n",
       "      <td>confession</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>My wife leaves me home alone with the dogs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>121</td>\n",
       "      <td>CrappyDesign</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>Babe, this negative space is amazing, let's ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001</th>\n",
       "      <td>65</td>\n",
       "      <td>StoppedWorking</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>Legs.exe update has a bug in it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5002</th>\n",
       "      <td>59</td>\n",
       "      <td>explainlikeimfive</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>ELI5: Why do pictures of a computer screen loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5003</th>\n",
       "      <td>33</td>\n",
       "      <td>NotMyJob</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>Put out the cooking magazines, boss!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5004</th>\n",
       "      <td>16</td>\n",
       "      <td>tuckedinkitties</td>\n",
       "      <td>7 hours ago</td>\n",
       "      <td>Post Zoomies Wind down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>16</td>\n",
       "      <td>BikiniBottomTwitter</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>Happens to the best of us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>35</td>\n",
       "      <td>mildlyinfuriating</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>Discovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>27</td>\n",
       "      <td>Perfectfit</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>This new printer I bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5008</th>\n",
       "      <td>92</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>TIL the Great Lakes have at least 6,000 shipwr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>44</td>\n",
       "      <td>AbandonedPorn</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>The abandoned house in the pumpkin field [OC] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>48</td>\n",
       "      <td>memes</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>Its a woofer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>123</td>\n",
       "      <td>FortNiteBR</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>Lv100 Season 3 Skin LEAKED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>445</td>\n",
       "      <td>news</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Levy County School District announced any stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>38</td>\n",
       "      <td>AnimalsBeingBros</td>\n",
       "      <td>8 hours ago</td>\n",
       "      <td>The dog was on time out, and got sent to his c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>127</td>\n",
       "      <td>howto</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>How to clean, maintain, and season a cast iron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>223</td>\n",
       "      <td>vexillology</td>\n",
       "      <td>11 hours ago</td>\n",
       "      <td>FIFA's solution to making flags with union Jac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>33</td>\n",
       "      <td>AskHistorians</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>I live in a European city where they have foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017</th>\n",
       "      <td>3034</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>What's a joke that's so stupid it's funny?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5018</th>\n",
       "      <td>26</td>\n",
       "      <td>zelda</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Today Is Legend Of Zelda's 32nd Anniversary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>281</td>\n",
       "      <td>CampingandHiking</td>\n",
       "      <td>14 hours ago</td>\n",
       "      <td>My cousin is suicidal and believed to be in a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>18</td>\n",
       "      <td>sbubby</td>\n",
       "      <td>5 hours ago</td>\n",
       "      <td>4 for one :)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5021</th>\n",
       "      <td>25</td>\n",
       "      <td>submechanophobia</td>\n",
       "      <td>4 hours ago</td>\n",
       "      <td>Imagine falling off from a gust of wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5022</th>\n",
       "      <td>66</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>TIL Billy Graham bailed Martin Luther King out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5023</th>\n",
       "      <td>244</td>\n",
       "      <td>confession</td>\n",
       "      <td>6 hours ago</td>\n",
       "      <td>My wife leaves me home alone with the dogs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5024</th>\n",
       "      <td>203</td>\n",
       "      <td>battlestations</td>\n",
       "      <td>10 hours ago</td>\n",
       "      <td>New Apartment, New battlestation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5025 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     comments            subreddit          time  \\\n",
       "0        4193                 pics   3 hours ago   \n",
       "1         337        todayilearned   5 hours ago   \n",
       "2         528           web_design   3 hours ago   \n",
       "3         743        UpliftingNews   5 hours ago   \n",
       "4         740          LifeProTips   4 hours ago   \n",
       "5        1593             woahdude   5 hours ago   \n",
       "6          83             Patriots   5 hours ago   \n",
       "7        1912                funny   5 hours ago   \n",
       "8         676                 gifs   4 hours ago   \n",
       "9         182                PandR   6 hours ago   \n",
       "10        377          MadeMeSmile   5 hours ago   \n",
       "11       1872                 pics   6 hours ago   \n",
       "12         76               likeus   6 hours ago   \n",
       "13        522         MovieDetails   7 hours ago   \n",
       "14        605        Wellthatsucks   6 hours ago   \n",
       "15        161               movies   4 hours ago   \n",
       "16       1275                space   8 hours ago   \n",
       "17        131            tiltshift   5 hours ago   \n",
       "18        690                  aww   8 hours ago   \n",
       "19        168             BeAmazed   3 hours ago   \n",
       "20        175            Eyebleach   7 hours ago   \n",
       "21        431     photoshopbattles   7 hours ago   \n",
       "22       1527    mildlyinteresting   8 hours ago   \n",
       "23        292             facepalm   7 hours ago   \n",
       "24        335           CozyPlaces   6 hours ago   \n",
       "25        260      Shitty_Car_Mods   9 hours ago   \n",
       "26        173                  DnD   8 hours ago   \n",
       "27        724                books   8 hours ago   \n",
       "28       1058              science  11 hours ago   \n",
       "29        274    IDontWorkHereLady   7 hours ago   \n",
       "...       ...                  ...           ...   \n",
       "4995      281     CampingandHiking  14 hours ago   \n",
       "4996       18               sbubby   5 hours ago   \n",
       "4997       25     submechanophobia   4 hours ago   \n",
       "4998       66        todayilearned   2 hours ago   \n",
       "4999      244           confession   6 hours ago   \n",
       "5000      121         CrappyDesign  12 hours ago   \n",
       "5001       65       StoppedWorking  10 hours ago   \n",
       "5002       59    explainlikeimfive   2 hours ago   \n",
       "5003       33             NotMyJob  10 hours ago   \n",
       "5004       16      tuckedinkitties   7 hours ago   \n",
       "5005       16  BikiniBottomTwitter   9 hours ago   \n",
       "5006       35    mildlyinfuriating   2 hours ago   \n",
       "5007       27           Perfectfit   5 hours ago   \n",
       "5008       92        todayilearned   4 hours ago   \n",
       "5009       44        AbandonedPorn   6 hours ago   \n",
       "5010       48                memes   9 hours ago   \n",
       "5011      123           FortNiteBR   6 hours ago   \n",
       "5012      445                 news   4 hours ago   \n",
       "5013       38     AnimalsBeingBros   8 hours ago   \n",
       "5014      127                howto   6 hours ago   \n",
       "5015      223          vexillology  11 hours ago   \n",
       "5016       33        AskHistorians   6 hours ago   \n",
       "5017     3034            AskReddit  10 hours ago   \n",
       "5018       26                zelda   4 hours ago   \n",
       "5019      281     CampingandHiking  14 hours ago   \n",
       "5020       18               sbubby   5 hours ago   \n",
       "5021       25     submechanophobia   4 hours ago   \n",
       "5022       66        todayilearned   2 hours ago   \n",
       "5023      244           confession   6 hours ago   \n",
       "5024      203       battlestations  10 hours ago   \n",
       "\n",
       "                                                  title  \n",
       "0     This is what democracy looks like. View from t...  \n",
       "1     TIL a party boat carrying sixty men and women ...  \n",
       "2                                 Animated login avatar  \n",
       "3     Peter Wang, a 15-year-old member of the Junior...  \n",
       "4     LPT: Keep a separate master resume with ALL pr...  \n",
       "5           First image ever taken of the Hydrogen Atom  \n",
       "6     Comprehensive look at just how good we've had ...  \n",
       "7                                    Not a method actor  \n",
       "8                        I'm gonna eat you little fishy  \n",
       "9         Donna's Contribution to Pawnee's Time Capsule  \n",
       "10                               Seizing an opportunity  \n",
       "11    On the left: Scene from the first season of St...  \n",
       "12                                           Dog Thinks  \n",
       "13    At the end of Ferris Bueller’s Day Off, he app...  \n",
       "14    Trucker forgot he was driving a tractor traile...  \n",
       "15    The Movie \"Cloudy with a Chance of Meatballs\" ...  \n",
       "16    Elon Musk on Twitter: High altitude wind shear...  \n",
       "17                                    My First Attempt.  \n",
       "18    Tank Puppy sees snow for the firs time at the ...  \n",
       "19                        Smooth Move On The Skateboard  \n",
       "20                     We still like cute goats, right?  \n",
       "21                   PsBattle: Dirty Cat in a Rail Yard  \n",
       "22           This morning reflection from my front door  \n",
       "23                                                 WOW!  \n",
       "24    Woke up to a white world, gonna enjoy it from ...  \n",
       "25                      I thought I was having a stroke  \n",
       "26                           So, my mom rolled a druid.  \n",
       "27    Amazon confirm they will be adapting Iain M Ba...  \n",
       "28    How a person responds to a difficult life even...  \n",
       "29                   Pour water on me, Lose your money.  \n",
       "...                                                 ...  \n",
       "4995  My cousin is suicidal and believed to be in a ...  \n",
       "4996                                       4 for one :)  \n",
       "4997            Imagine falling off from a gust of wind  \n",
       "4998  TIL Billy Graham bailed Martin Luther King out...  \n",
       "4999        My wife leaves me home alone with the dogs.  \n",
       "5000  Babe, this negative space is amazing, let's ge...  \n",
       "5001                    Legs.exe update has a bug in it  \n",
       "5002  ELI5: Why do pictures of a computer screen loo...  \n",
       "5003               Put out the cooking magazines, boss!  \n",
       "5004                             Post Zoomies Wind down  \n",
       "5005                          Happens to the best of us  \n",
       "5006                                          Discovery  \n",
       "5007                          This new printer I bought  \n",
       "5008  TIL the Great Lakes have at least 6,000 shipwr...  \n",
       "5009  The abandoned house in the pumpkin field [OC] ...  \n",
       "5010                                       Its a woofer  \n",
       "5011                         Lv100 Season 3 Skin LEAKED  \n",
       "5012  Levy County School District announced any stud...  \n",
       "5013  The dog was on time out, and got sent to his c...  \n",
       "5014  How to clean, maintain, and season a cast iron...  \n",
       "5015  FIFA's solution to making flags with union Jac...  \n",
       "5016  I live in a European city where they have foun...  \n",
       "5017         What's a joke that's so stupid it's funny?  \n",
       "5018        Today Is Legend Of Zelda's 32nd Anniversary  \n",
       "5019  My cousin is suicidal and believed to be in a ...  \n",
       "5020                                       4 for one :)  \n",
       "5021            Imagine falling off from a gust of wind  \n",
       "5022  TIL Billy Graham bailed Martin Luther King out...  \n",
       "5023        My wife leaves me home alone with the dogs.  \n",
       "5024                   New Apartment, New battlestation  \n",
       "\n",
       "[5025 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##concat dataframes\n",
    "\n",
    "frames = [df1, df2]\n",
    "\n",
    "reddit = pd.concat(frames)\n",
    "reddit = reddit.reset_index(drop=True)\n",
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5025, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comments     315\n",
       "subreddit    246\n",
       "time          20\n",
       "title        309\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We have so many duplicates.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV\n",
    "You may do this regularly while scraping data as well, so that if your scraper stops of your computer crashes, you don't lose all your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "reddit.to_csv('data_reddit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data using PRAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open ('apipass.json') as f :\n",
    "    keys = json.loads(f.read())\n",
    "\n",
    "reddit = praw.Reddit(client_id= keys['client_id'], client_secret=keys['client_secret'],\n",
    "                     username= keys['username'], password= keys['password'], \n",
    "                     user_agent= keys['user_agent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "hot_posts =  reddit.subreddit('all').hot(limit=5000)\n",
    "\n",
    "hot_list = []\n",
    "for submit in hot_posts:\n",
    "    if not submit.stickied:\n",
    "        hot = {}\n",
    "        hot['title'] = submit.title\n",
    "        hot['votes'] = submit.ups\n",
    "        hot['comments'] = submit.num_comments\n",
    "        hot['date_created'] = datetime.datetime.fromtimestamp(submit.created)\n",
    "        #hot['is_video'] = submit.is_video\n",
    "        hot['subreddit'] = submit.subreddit\n",
    "        hot_list.append(hot)\n",
    "        \n",
    "hot_df = pd.DataFrame(hot_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1450</td>\n",
       "      <td>2018-02-21 22:07:58</td>\n",
       "      <td>nba</td>\n",
       "      <td>Wow the Warriors are really good now. Is Steph...</td>\n",
       "      <td>13927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>535</td>\n",
       "      <td>2018-02-21 20:43:34</td>\n",
       "      <td>web_design</td>\n",
       "      <td>Animated login avatar</td>\n",
       "      <td>38056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4499</td>\n",
       "      <td>2018-02-21 21:33:31</td>\n",
       "      <td>pics</td>\n",
       "      <td>This is what democracy looks like. View from t...</td>\n",
       "      <td>32488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366</td>\n",
       "      <td>2018-02-21 20:24:23</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>TIL a party boat carrying sixty men and women ...</td>\n",
       "      <td>16878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745</td>\n",
       "      <td>2018-02-21 19:58:15</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>LPT: Keep a separate master resume with ALL pr...</td>\n",
       "      <td>41262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   comments        date_created      subreddit  \\\n",
       "0      1450 2018-02-21 22:07:58            nba   \n",
       "1       535 2018-02-21 20:43:34     web_design   \n",
       "2      4499 2018-02-21 21:33:31           pics   \n",
       "3       366 2018-02-21 20:24:23  todayilearned   \n",
       "4       745 2018-02-21 19:58:15    LifeProTips   \n",
       "\n",
       "                                               title  votes  \n",
       "0  Wow the Warriors are really good now. Is Steph...  13927  \n",
       "1                              Animated login avatar  38056  \n",
       "2  This is what democracy looks like. View from t...  32488  \n",
       "3  TIL a party boat carrying sixty men and women ...  16878  \n",
       "4  LPT: Keep a separate master resume with ALL pr...  41262  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comments         450\n",
       "date_created    4677\n",
       "subreddit       2446\n",
       "title           4779\n",
       "votes           1559\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hot_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "hot_df.to_csv('data_redditv2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting comments using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_redditv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4971 entries, 0 to 4970\n",
      "Data columns (total 6 columns):\n",
      "Unnamed: 0      4971 non-null int64\n",
      "comments        4971 non-null int64\n",
      "date_created    4971 non-null object\n",
      "subreddit       4971 non-null object\n",
      "title           4971 non-null object\n",
      "votes           4971 non-null int64\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 233.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1450</td>\n",
       "      <td>2018-02-21 22:07:58</td>\n",
       "      <td>nba</td>\n",
       "      <td>Wow the Warriors are really good now. Is Steph...</td>\n",
       "      <td>13927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>535</td>\n",
       "      <td>2018-02-21 20:43:34</td>\n",
       "      <td>web_design</td>\n",
       "      <td>Animated login avatar</td>\n",
       "      <td>38056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4499</td>\n",
       "      <td>2018-02-21 21:33:31</td>\n",
       "      <td>pics</td>\n",
       "      <td>This is what democracy looks like. View from t...</td>\n",
       "      <td>32488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>2018-02-21 20:24:23</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>TIL a party boat carrying sixty men and women ...</td>\n",
       "      <td>16878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>745</td>\n",
       "      <td>2018-02-21 19:58:15</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>LPT: Keep a separate master resume with ALL pr...</td>\n",
       "      <td>41262</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  comments         date_created      subreddit  \\\n",
       "0           0      1450  2018-02-21 22:07:58            nba   \n",
       "1           1       535  2018-02-21 20:43:34     web_design   \n",
       "2           2      4499  2018-02-21 21:33:31           pics   \n",
       "3           3       366  2018-02-21 20:24:23  todayilearned   \n",
       "4           4       745  2018-02-21 19:58:15    LifeProTips   \n",
       "\n",
       "                                               title  votes  \n",
       "0  Wow the Warriors are really good now. Is Steph...  13927  \n",
       "1                              Animated login avatar  38056  \n",
       "2  This is what democracy looks like. View from t...  32488  \n",
       "3  TIL a party boat carrying sixty men and women ...  16878  \n",
       "4  LPT: Keep a separate master resume with ALL pr...  41262  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1450</td>\n",
       "      <td>2018-02-21 22:07:58</td>\n",
       "      <td>nba</td>\n",
       "      <td>Wow the Warriors are really good now. Is Steph...</td>\n",
       "      <td>13927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>535</td>\n",
       "      <td>2018-02-21 20:43:34</td>\n",
       "      <td>web_design</td>\n",
       "      <td>Animated login avatar</td>\n",
       "      <td>38056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4499</td>\n",
       "      <td>2018-02-21 21:33:31</td>\n",
       "      <td>pics</td>\n",
       "      <td>This is what democracy looks like. View from t...</td>\n",
       "      <td>32488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366</td>\n",
       "      <td>2018-02-21 20:24:23</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>TIL a party boat carrying sixty men and women ...</td>\n",
       "      <td>16878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745</td>\n",
       "      <td>2018-02-21 19:58:15</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>LPT: Keep a separate master resume with ALL pr...</td>\n",
       "      <td>41262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107</td>\n",
       "      <td>2018-02-21 21:59:42</td>\n",
       "      <td>me_irl</td>\n",
       "      <td>me irl</td>\n",
       "      <td>7289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>2018-02-21 19:31:19</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>First image ever taken of the Hydrogen Atom</td>\n",
       "      <td>47806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1943</td>\n",
       "      <td>2018-02-21 19:29:31</td>\n",
       "      <td>funny</td>\n",
       "      <td>Not a method actor</td>\n",
       "      <td>39035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>699</td>\n",
       "      <td>2018-02-21 20:03:32</td>\n",
       "      <td>gifs</td>\n",
       "      <td>I'm gonna eat you little fishy</td>\n",
       "      <td>25085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6028</td>\n",
       "      <td>2018-02-21 19:49:26</td>\n",
       "      <td>politics</td>\n",
       "      <td>The right-wing sliming of Douglas High student...</td>\n",
       "      <td>40367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>758</td>\n",
       "      <td>2018-02-21 19:37:51</td>\n",
       "      <td>UpliftingNews</td>\n",
       "      <td>Peter Wang, a 15-year-old member of the Junior...</td>\n",
       "      <td>25634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>385</td>\n",
       "      <td>2018-02-21 19:45:40</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td>Seizing an opportunity</td>\n",
       "      <td>19357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>171</td>\n",
       "      <td>2018-02-21 21:35:21</td>\n",
       "      <td>BeAmazed</td>\n",
       "      <td>Smooth Move On The Skateboard</td>\n",
       "      <td>7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>535</td>\n",
       "      <td>2018-02-21 23:34:27</td>\n",
       "      <td>soccer</td>\n",
       "      <td>Great save by David Gea vs Sevilla</td>\n",
       "      <td>3465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>337</td>\n",
       "      <td>2018-02-21 19:15:37</td>\n",
       "      <td>CozyPlaces</td>\n",
       "      <td>Woke up to a white world, gonna enjoy it from ...</td>\n",
       "      <td>15400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>134</td>\n",
       "      <td>2018-02-21 19:40:45</td>\n",
       "      <td>tiltshift</td>\n",
       "      <td>My First Attempt.</td>\n",
       "      <td>14669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>2018-02-21 20:08:11</td>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>8649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>510</td>\n",
       "      <td>2018-02-21 19:25:23</td>\n",
       "      <td>movies</td>\n",
       "      <td>Netflix Lands Worldwide Rights to Next Four Du...</td>\n",
       "      <td>9067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77</td>\n",
       "      <td>2018-02-21 19:16:55</td>\n",
       "      <td>likeus</td>\n",
       "      <td>Dog Thinks</td>\n",
       "      <td>10598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3283</td>\n",
       "      <td>2018-02-21 19:51:09</td>\n",
       "      <td>beholdthemasterrace</td>\n",
       "      <td>Nazi manlet trying to spread his \"wisdom\". Get...</td>\n",
       "      <td>10312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>185</td>\n",
       "      <td>2018-02-21 18:58:33</td>\n",
       "      <td>PandR</td>\n",
       "      <td>Donna's Contribution to Pawnee's Time Capsule</td>\n",
       "      <td>9945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>451</td>\n",
       "      <td>2018-02-21 18:10:16</td>\n",
       "      <td>ANormalDayInRussia</td>\n",
       "      <td>hmmm...</td>\n",
       "      <td>19715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>612</td>\n",
       "      <td>2018-02-21 17:57:33</td>\n",
       "      <td>Wellthatsucks</td>\n",
       "      <td>Trucker forgot he was driving a tractor traile...</td>\n",
       "      <td>17546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>431</td>\n",
       "      <td>2018-02-21 17:51:34</td>\n",
       "      <td>photoshopbattles</td>\n",
       "      <td>PsBattle: Dirty Cat in a Rail Yard</td>\n",
       "      <td>38553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>530</td>\n",
       "      <td>2018-02-21 18:12:06</td>\n",
       "      <td>MovieDetails</td>\n",
       "      <td>At the end of Ferris Bueller’s Day Off, he app...</td>\n",
       "      <td>15328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1108</td>\n",
       "      <td>2018-02-21 17:26:26</td>\n",
       "      <td>technology</td>\n",
       "      <td>Ajit Pai’s Plan Will Take Broadband Away From ...</td>\n",
       "      <td>21504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>696</td>\n",
       "      <td>2018-02-21 17:05:02</td>\n",
       "      <td>aww</td>\n",
       "      <td>Tank Puppy sees snow for the firs time at the ...</td>\n",
       "      <td>50704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>297</td>\n",
       "      <td>2018-02-21 18:15:54</td>\n",
       "      <td>facepalm</td>\n",
       "      <td>WOW!</td>\n",
       "      <td>15621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>67</td>\n",
       "      <td>2018-02-21 20:58:28</td>\n",
       "      <td>NatureIsFuckingLit</td>\n",
       "      <td>Scaring off 2 fish with active camouflage is l...</td>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1280</td>\n",
       "      <td>2018-02-21 17:24:30</td>\n",
       "      <td>space</td>\n",
       "      <td>Elon Musk on Twitter: High altitude wind shear...</td>\n",
       "      <td>35754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-21 20:04:44</td>\n",
       "      <td>PropagandaPosters</td>\n",
       "      <td>Russian Anti-Ottoman Propaganda 1915</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>37</td>\n",
       "      <td>2018-02-21 19:25:33</td>\n",
       "      <td>boxoffice</td>\n",
       "      <td>[NA] Black Panther’ Posts Record $21M Pre-Summ...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>6</td>\n",
       "      <td>2018-02-21 19:25:35</td>\n",
       "      <td>The_Mueller</td>\n",
       "      <td>Years of Public Service: .92</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-22 00:12:24</td>\n",
       "      <td>KendrickLamar</td>\n",
       "      <td>Kendrick Lamar wins international male at the ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-02-21 22:05:21</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>My pup on a canoe trip, done by Amanda Cancill...</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>38</td>\n",
       "      <td>2018-02-21 17:27:30</td>\n",
       "      <td>Guildwars2</td>\n",
       "      <td>Looking for a Path of Fire playthrough on Char...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>17</td>\n",
       "      <td>2018-02-21 21:12:07</td>\n",
       "      <td>funny</td>\n",
       "      <td>Can't even make coffee without the fear of bei...</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>262</td>\n",
       "      <td>2018-02-21 07:07:24</td>\n",
       "      <td>PUBGXboxOne</td>\n",
       "      <td>Be Like Bill</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>13</td>\n",
       "      <td>2018-02-21 17:41:32</td>\n",
       "      <td>bicycling</td>\n",
       "      <td>Woman in Turkey seeks divorce over husband's b...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>14</td>\n",
       "      <td>2018-02-21 19:03:03</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>During sex with my wife,</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4951</th>\n",
       "      <td>203</td>\n",
       "      <td>2018-02-21 16:42:21</td>\n",
       "      <td>NASCAR</td>\n",
       "      <td>Harvick : Drivers are not happy with Denny Ham...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4952</th>\n",
       "      <td>11</td>\n",
       "      <td>2018-02-21 16:16:45</td>\n",
       "      <td>mylittlepony</td>\n",
       "      <td>pony_irl</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4953</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-02-21 21:25:42</td>\n",
       "      <td>ass</td>\n",
       "      <td>Fucking Your Head Up. . . ;]</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4954</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-02-21 19:42:28</td>\n",
       "      <td>parrots</td>\n",
       "      <td>Sully got a lil car sick on the way to their y...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4955</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-02-21 20:10:53</td>\n",
       "      <td>JiggleFuck</td>\n",
       "      <td>That nice jiggle</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4956</th>\n",
       "      <td>9</td>\n",
       "      <td>2018-02-21 16:40:33</td>\n",
       "      <td>PUBG</td>\n",
       "      <td>Battlefeels. All Credit to: Melvin Pro Gamer</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4957</th>\n",
       "      <td>88</td>\n",
       "      <td>2018-02-21 23:11:14</td>\n",
       "      <td>unpopularopinion</td>\n",
       "      <td>Children should not be allowed to be taught re...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-21 18:45:16</td>\n",
       "      <td>RealGirls</td>\n",
       "      <td>What lifeguard stereotypes are made of</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>5</td>\n",
       "      <td>2018-02-21 19:17:51</td>\n",
       "      <td>im14andthisisdeep</td>\n",
       "      <td>but... why?</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-02-21 22:30:44</td>\n",
       "      <td>RotMG</td>\n",
       "      <td>DECA selling UTs in mystery boxes now smh</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-02-21 23:31:00</td>\n",
       "      <td>bostonceltics</td>\n",
       "      <td>In December of 1964, Tom \"Satch\" Sanders, Sam ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>226</td>\n",
       "      <td>2018-02-21 15:07:32</td>\n",
       "      <td>blackdesertonline</td>\n",
       "      <td>Absolute skills coming next week</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>22</td>\n",
       "      <td>2018-02-21 19:04:20</td>\n",
       "      <td>heroesofthestorm</td>\n",
       "      <td>Wanted to sketch up a skin idea for our little...</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-02-22 00:04:38</td>\n",
       "      <td>litecoin</td>\n",
       "      <td>Doodle from he USS Chikun (2019)</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-02-21 20:16:42</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>A seemingly surprised traffic sign</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>14</td>\n",
       "      <td>2018-02-21 22:26:14</td>\n",
       "      <td>jailbreak</td>\n",
       "      <td>[Question] Original ios dock. Saw this a while...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>30</td>\n",
       "      <td>2018-02-21 14:24:22</td>\n",
       "      <td>Animemes</td>\n",
       "      <td>Fall in The Web of Desire</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>59</td>\n",
       "      <td>2018-02-21 17:14:38</td>\n",
       "      <td>kancolle</td>\n",
       "      <td>[Media] Zuihou Kai Ni &amp; Kai Ni B</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-02-21 20:42:22</td>\n",
       "      <td>curledfeetsies</td>\n",
       "      <td>Curled feetsies while keeping the sick person ...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>8</td>\n",
       "      <td>2018-02-21 12:51:25</td>\n",
       "      <td>nsfw</td>\n",
       "      <td>Naked</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4961 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comments         date_created            subreddit  \\\n",
       "0         1450  2018-02-21 22:07:58                  nba   \n",
       "1          535  2018-02-21 20:43:34           web_design   \n",
       "2         4499  2018-02-21 21:33:31                 pics   \n",
       "3          366  2018-02-21 20:24:23        todayilearned   \n",
       "4          745  2018-02-21 19:58:15          LifeProTips   \n",
       "5          107  2018-02-21 21:59:42               me_irl   \n",
       "6         1600  2018-02-21 19:31:19             woahdude   \n",
       "7         1943  2018-02-21 19:29:31                funny   \n",
       "8          699  2018-02-21 20:03:32                 gifs   \n",
       "9         6028  2018-02-21 19:49:26             politics   \n",
       "10         758  2018-02-21 19:37:51        UpliftingNews   \n",
       "11         385  2018-02-21 19:45:40          MadeMeSmile   \n",
       "12         171  2018-02-21 21:35:21             BeAmazed   \n",
       "13         535  2018-02-21 23:34:27               soccer   \n",
       "14         337  2018-02-21 19:15:37           CozyPlaces   \n",
       "15         134  2018-02-21 19:40:45            tiltshift   \n",
       "16          50  2018-02-21 20:08:11         2meirl4meirl   \n",
       "17         510  2018-02-21 19:25:23               movies   \n",
       "18          77  2018-02-21 19:16:55               likeus   \n",
       "19        3283  2018-02-21 19:51:09  beholdthemasterrace   \n",
       "20         185  2018-02-21 18:58:33                PandR   \n",
       "21         451  2018-02-21 18:10:16   ANormalDayInRussia   \n",
       "22         612  2018-02-21 17:57:33        Wellthatsucks   \n",
       "23         431  2018-02-21 17:51:34     photoshopbattles   \n",
       "24         530  2018-02-21 18:12:06         MovieDetails   \n",
       "25        1108  2018-02-21 17:26:26           technology   \n",
       "26         696  2018-02-21 17:05:02                  aww   \n",
       "27         297  2018-02-21 18:15:54             facepalm   \n",
       "28          67  2018-02-21 20:58:28   NatureIsFuckingLit   \n",
       "29        1280  2018-02-21 17:24:30                space   \n",
       "...        ...                  ...                  ...   \n",
       "4941         2  2018-02-21 20:04:44    PropagandaPosters   \n",
       "4942        37  2018-02-21 19:25:33            boxoffice   \n",
       "4943         6  2018-02-21 19:25:35          The_Mueller   \n",
       "4944         1  2018-02-22 00:12:24        KendrickLamar   \n",
       "4945         4  2018-02-21 22:05:21              tattoos   \n",
       "4946        38  2018-02-21 17:27:30           Guildwars2   \n",
       "4947        17  2018-02-21 21:12:07                funny   \n",
       "4948       262  2018-02-21 07:07:24          PUBGXboxOne   \n",
       "4949        13  2018-02-21 17:41:32            bicycling   \n",
       "4950        14  2018-02-21 19:03:03                Jokes   \n",
       "4951       203  2018-02-21 16:42:21               NASCAR   \n",
       "4952        11  2018-02-21 16:16:45         mylittlepony   \n",
       "4953         7  2018-02-21 21:25:42                  ass   \n",
       "4954         3  2018-02-21 19:42:28              parrots   \n",
       "4955         8  2018-02-21 20:10:53           JiggleFuck   \n",
       "4956         9  2018-02-21 16:40:33                 PUBG   \n",
       "4957        88  2018-02-21 23:11:14     unpopularopinion   \n",
       "4958         1  2018-02-21 18:45:16            RealGirls   \n",
       "4959         5  2018-02-21 19:17:51    im14andthisisdeep   \n",
       "4960         7  2018-02-21 22:30:44                RotMG   \n",
       "4961         8  2018-02-21 23:31:00        bostonceltics   \n",
       "4962       226  2018-02-21 15:07:32    blackdesertonline   \n",
       "4963        22  2018-02-21 19:04:20     heroesofthestorm   \n",
       "4964         2  2018-02-22 00:04:38             litecoin   \n",
       "4965         7  2018-02-21 20:16:42    mildlyinteresting   \n",
       "4966        14  2018-02-21 22:26:14            jailbreak   \n",
       "4967        30  2018-02-21 14:24:22             Animemes   \n",
       "4968        59  2018-02-21 17:14:38             kancolle   \n",
       "4969         1  2018-02-21 20:42:22       curledfeetsies   \n",
       "4970         8  2018-02-21 12:51:25                 nsfw   \n",
       "\n",
       "                                                  title  votes  \n",
       "0     Wow the Warriors are really good now. Is Steph...  13927  \n",
       "1                                 Animated login avatar  38056  \n",
       "2     This is what democracy looks like. View from t...  32488  \n",
       "3     TIL a party boat carrying sixty men and women ...  16878  \n",
       "4     LPT: Keep a separate master resume with ALL pr...  41262  \n",
       "5                                                me irl   7289  \n",
       "6           First image ever taken of the Hydrogen Atom  47806  \n",
       "7                                    Not a method actor  39035  \n",
       "8                        I'm gonna eat you little fishy  25085  \n",
       "9     The right-wing sliming of Douglas High student...  40367  \n",
       "10    Peter Wang, a 15-year-old member of the Junior...  25634  \n",
       "11                               Seizing an opportunity  19357  \n",
       "12                        Smooth Move On The Skateboard   7268  \n",
       "13                   Great save by David Gea vs Sevilla   3465  \n",
       "14    Woke up to a white world, gonna enjoy it from ...  15400  \n",
       "15                                    My First Attempt.  14669  \n",
       "16                                         2meirl4meirl   8649  \n",
       "17    Netflix Lands Worldwide Rights to Next Four Du...   9067  \n",
       "18                                           Dog Thinks  10598  \n",
       "19    Nazi manlet trying to spread his \"wisdom\". Get...  10312  \n",
       "20        Donna's Contribution to Pawnee's Time Capsule   9945  \n",
       "21                                              hmmm...  19715  \n",
       "22    Trucker forgot he was driving a tractor traile...  17546  \n",
       "23                   PsBattle: Dirty Cat in a Rail Yard  38553  \n",
       "24    At the end of Ferris Bueller’s Day Off, he app...  15328  \n",
       "25    Ajit Pai’s Plan Will Take Broadband Away From ...  21504  \n",
       "26    Tank Puppy sees snow for the firs time at the ...  50704  \n",
       "27                                                 WOW!  15621  \n",
       "28    Scaring off 2 fish with active camouflage is l...   4567  \n",
       "29    Elon Musk on Twitter: High altitude wind shear...  35754  \n",
       "...                                                 ...    ...  \n",
       "4941               Russian Anti-Ottoman Propaganda 1915     57  \n",
       "4942  [NA] Black Panther’ Posts Record $21M Pre-Summ...     63  \n",
       "4943                       Years of Public Service: .92    108  \n",
       "4944  Kendrick Lamar wins international male at the ...     26  \n",
       "4945  My pup on a canoe trip, done by Amanda Cancill...    122  \n",
       "4946  Looking for a Path of Fire playthrough on Char...     94  \n",
       "4947  Can't even make coffee without the fear of bei...    809  \n",
       "4948                                       Be Like Bill   1104  \n",
       "4949  Woman in Turkey seeks divorce over husband's b...     90  \n",
       "4950                           During sex with my wife,    211  \n",
       "4951  Harvick : Drivers are not happy with Denny Ham...    183  \n",
       "4952                                           pony_irl    108  \n",
       "4953                       Fucking Your Head Up. . . ;]     76  \n",
       "4954  Sully got a lil car sick on the way to their y...     61  \n",
       "4955                                   That nice jiggle     55  \n",
       "4956       Battlefeels. All Credit to: Melvin Pro Gamer    103  \n",
       "4957  Children should not be allowed to be taught re...     32  \n",
       "4958             What lifeguard stereotypes are made of    123  \n",
       "4959                                        but... why?    114  \n",
       "4960          DECA selling UTs in mystery boxes now smh     40  \n",
       "4961  In December of 1964, Tom \"Satch\" Sanders, Sam ...     30  \n",
       "4962                   Absolute skills coming next week    140  \n",
       "4963  Wanted to sketch up a skin idea for our little...    210  \n",
       "4964                   Doodle from he USS Chikun (2019)     26  \n",
       "4965                 A seemingly surprised traffic sign    172  \n",
       "4966  [Question] Original ios dock. Saw this a while...     34  \n",
       "4967                          Fall in The Web of Desire    867  \n",
       "4968                   [Media] Zuihou Kai Ni & Kai Ni B     95  \n",
       "4969  Curled feetsies while keeping the sick person ...     48  \n",
       "4970                                              Naked    639  \n",
       "\n",
       "[4961 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['comments'] = data['comments'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4971.000000\n",
       "mean       76.020720\n",
       "std       310.959539\n",
       "min         0.000000\n",
       "25%         5.000000\n",
       "50%        16.000000\n",
       "75%        47.000000\n",
       "max      6381.000000\n",
       "Name: comments, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['comments'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16bef2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(data['comments'], color='orange');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comments</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2107</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3586</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4136</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4472</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5778</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6381</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          subreddit\n",
       "comments           \n",
       "0               180\n",
       "1               232\n",
       "2               241\n",
       "3               212\n",
       "4               199\n",
       "5               194\n",
       "6               186\n",
       "7               157\n",
       "8               143\n",
       "9               115\n",
       "10              117\n",
       "11              108\n",
       "12               98\n",
       "13              100\n",
       "14               75\n",
       "15               91\n",
       "16               61\n",
       "17               71\n",
       "18               66\n",
       "19               59\n",
       "20               58\n",
       "21               65\n",
       "22               52\n",
       "23               61\n",
       "24               54\n",
       "25               56\n",
       "26               53\n",
       "27               33\n",
       "28               44\n",
       "29               43\n",
       "...             ...\n",
       "1698              1\n",
       "1705              1\n",
       "1801              1\n",
       "1811              1\n",
       "1877              1\n",
       "1943              1\n",
       "1998              1\n",
       "2060              1\n",
       "2064              1\n",
       "2107              1\n",
       "2117              1\n",
       "2188              1\n",
       "2627              1\n",
       "2942              1\n",
       "3038              1\n",
       "3283              1\n",
       "3480              1\n",
       "3586              1\n",
       "3952              1\n",
       "3979              1\n",
       "4136              1\n",
       "4177              1\n",
       "4235              1\n",
       "4472              1\n",
       "4499              1\n",
       "5214              1\n",
       "5740              1\n",
       "5778              1\n",
       "6028              1\n",
       "6381              1\n",
       "\n",
       "[450 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['comments', 'subreddit']].groupby('comments').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the number of comments was low or high. Compute the median number of comments and create a new binary variable that is true when the number of comments is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the number of comments here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW number of comments.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extremely popular threads. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of comment numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "76.02072017702676\n",
      "47.0\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "#median number of comments\n",
    "\n",
    "from statistics import median\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "median_comments= median(data['comments'])\n",
    "mean_comments = np.mean(data['comments'])\n",
    "percentile_75 = np.percentile(data['comments'], 75)\n",
    "percentile_50 = np.percentile(data['comments'], 50)  # same as median\n",
    "\n",
    "\n",
    "print (median_comments)\n",
    "print (mean_comments)\n",
    "print (percentile_75)\n",
    "print (percentile_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['popular'] = [1 if x >= percentile_50 else 0 for x in data['comments']]\n",
    "#Binarizer does the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>date_created</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>votes</th>\n",
       "      <th>popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1450</td>\n",
       "      <td>2018-02-21 22:07:58</td>\n",
       "      <td>nba</td>\n",
       "      <td>Wow the Warriors are really good now. Is Steph...</td>\n",
       "      <td>13927</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>535</td>\n",
       "      <td>2018-02-21 20:43:34</td>\n",
       "      <td>web_design</td>\n",
       "      <td>Animated login avatar</td>\n",
       "      <td>38056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4499</td>\n",
       "      <td>2018-02-21 21:33:31</td>\n",
       "      <td>pics</td>\n",
       "      <td>This is what democracy looks like. View from t...</td>\n",
       "      <td>32488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366</td>\n",
       "      <td>2018-02-21 20:24:23</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>TIL a party boat carrying sixty men and women ...</td>\n",
       "      <td>16878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745</td>\n",
       "      <td>2018-02-21 19:58:15</td>\n",
       "      <td>LifeProTips</td>\n",
       "      <td>LPT: Keep a separate master resume with ALL pr...</td>\n",
       "      <td>41262</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107</td>\n",
       "      <td>2018-02-21 21:59:42</td>\n",
       "      <td>me_irl</td>\n",
       "      <td>me irl</td>\n",
       "      <td>7289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1600</td>\n",
       "      <td>2018-02-21 19:31:19</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>First image ever taken of the Hydrogen Atom</td>\n",
       "      <td>47806</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1943</td>\n",
       "      <td>2018-02-21 19:29:31</td>\n",
       "      <td>funny</td>\n",
       "      <td>Not a method actor</td>\n",
       "      <td>39035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>699</td>\n",
       "      <td>2018-02-21 20:03:32</td>\n",
       "      <td>gifs</td>\n",
       "      <td>I'm gonna eat you little fishy</td>\n",
       "      <td>25085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6028</td>\n",
       "      <td>2018-02-21 19:49:26</td>\n",
       "      <td>politics</td>\n",
       "      <td>The right-wing sliming of Douglas High student...</td>\n",
       "      <td>40367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>758</td>\n",
       "      <td>2018-02-21 19:37:51</td>\n",
       "      <td>UpliftingNews</td>\n",
       "      <td>Peter Wang, a 15-year-old member of the Junior...</td>\n",
       "      <td>25634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>385</td>\n",
       "      <td>2018-02-21 19:45:40</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td>Seizing an opportunity</td>\n",
       "      <td>19357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>171</td>\n",
       "      <td>2018-02-21 21:35:21</td>\n",
       "      <td>BeAmazed</td>\n",
       "      <td>Smooth Move On The Skateboard</td>\n",
       "      <td>7268</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>535</td>\n",
       "      <td>2018-02-21 23:34:27</td>\n",
       "      <td>soccer</td>\n",
       "      <td>Great save by David Gea vs Sevilla</td>\n",
       "      <td>3465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>337</td>\n",
       "      <td>2018-02-21 19:15:37</td>\n",
       "      <td>CozyPlaces</td>\n",
       "      <td>Woke up to a white world, gonna enjoy it from ...</td>\n",
       "      <td>15400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>134</td>\n",
       "      <td>2018-02-21 19:40:45</td>\n",
       "      <td>tiltshift</td>\n",
       "      <td>My First Attempt.</td>\n",
       "      <td>14669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>2018-02-21 20:08:11</td>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>8649</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>510</td>\n",
       "      <td>2018-02-21 19:25:23</td>\n",
       "      <td>movies</td>\n",
       "      <td>Netflix Lands Worldwide Rights to Next Four Du...</td>\n",
       "      <td>9067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>77</td>\n",
       "      <td>2018-02-21 19:16:55</td>\n",
       "      <td>likeus</td>\n",
       "      <td>Dog Thinks</td>\n",
       "      <td>10598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3283</td>\n",
       "      <td>2018-02-21 19:51:09</td>\n",
       "      <td>beholdthemasterrace</td>\n",
       "      <td>Nazi manlet trying to spread his \"wisdom\". Get...</td>\n",
       "      <td>10312</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    comments         date_created            subreddit  \\\n",
       "0       1450  2018-02-21 22:07:58                  nba   \n",
       "1        535  2018-02-21 20:43:34           web_design   \n",
       "2       4499  2018-02-21 21:33:31                 pics   \n",
       "3        366  2018-02-21 20:24:23        todayilearned   \n",
       "4        745  2018-02-21 19:58:15          LifeProTips   \n",
       "5        107  2018-02-21 21:59:42               me_irl   \n",
       "6       1600  2018-02-21 19:31:19             woahdude   \n",
       "7       1943  2018-02-21 19:29:31                funny   \n",
       "8        699  2018-02-21 20:03:32                 gifs   \n",
       "9       6028  2018-02-21 19:49:26             politics   \n",
       "10       758  2018-02-21 19:37:51        UpliftingNews   \n",
       "11       385  2018-02-21 19:45:40          MadeMeSmile   \n",
       "12       171  2018-02-21 21:35:21             BeAmazed   \n",
       "13       535  2018-02-21 23:34:27               soccer   \n",
       "14       337  2018-02-21 19:15:37           CozyPlaces   \n",
       "15       134  2018-02-21 19:40:45            tiltshift   \n",
       "16        50  2018-02-21 20:08:11         2meirl4meirl   \n",
       "17       510  2018-02-21 19:25:23               movies   \n",
       "18        77  2018-02-21 19:16:55               likeus   \n",
       "19      3283  2018-02-21 19:51:09  beholdthemasterrace   \n",
       "\n",
       "                                                title  votes  popular  \n",
       "0   Wow the Warriors are really good now. Is Steph...  13927        1  \n",
       "1                               Animated login avatar  38056        1  \n",
       "2   This is what democracy looks like. View from t...  32488        1  \n",
       "3   TIL a party boat carrying sixty men and women ...  16878        1  \n",
       "4   LPT: Keep a separate master resume with ALL pr...  41262        1  \n",
       "5                                              me irl   7289        1  \n",
       "6         First image ever taken of the Hydrogen Atom  47806        1  \n",
       "7                                  Not a method actor  39035        1  \n",
       "8                      I'm gonna eat you little fishy  25085        1  \n",
       "9   The right-wing sliming of Douglas High student...  40367        1  \n",
       "10  Peter Wang, a 15-year-old member of the Junior...  25634        1  \n",
       "11                             Seizing an opportunity  19357        1  \n",
       "12                      Smooth Move On The Skateboard   7268        1  \n",
       "13                 Great save by David Gea vs Sevilla   3465        1  \n",
       "14  Woke up to a white world, gonna enjoy it from ...  15400        1  \n",
       "15                                  My First Attempt.  14669        1  \n",
       "16                                       2meirl4meirl   8649        1  \n",
       "17  Netflix Lands Worldwide Rights to Next Four Du...   9067        1  \n",
       "18                                         Dog Thinks  10598        1  \n",
       "19  Nazi manlet trying to spread his \"wisdom\". Get...  10312        1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2523\n",
       "0    2448\n",
       "Name: popular, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.popular.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "\n",
    "# baseline = median_comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low number of comments using Sklearn. Start by ONLY using the subreddit as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2446"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "politics               11\n",
       "funny                   9\n",
       "todayilearned           9\n",
       "dankmemes               8\n",
       "me_irl                  8\n",
       "aww                     8\n",
       "Overwatch               8\n",
       "Animemes                8\n",
       "pics                    8\n",
       "Rainbow6                8\n",
       "GlobalOffensive         8\n",
       "BlackPeopleTwitter      8\n",
       "soccer                  8\n",
       "nba                     8\n",
       "gaming                  8\n",
       "AskReddit               8\n",
       "gifs                    8\n",
       "rupaulsdragrace         7\n",
       "PeopleFuckingDying      7\n",
       "SquaredCircle           7\n",
       "2007scape               7\n",
       "FireEmblemHeroes        7\n",
       "oddlysatisfying         7\n",
       "tumblr                  7\n",
       "greentext               7\n",
       "PrequelMemes            7\n",
       "interestingasfuck       7\n",
       "videos                  7\n",
       "Tinder                  7\n",
       "leagueoflegends         7\n",
       "                       ..\n",
       "animelegwear            1\n",
       "AlexisRen               1\n",
       "GirlswithGlasses        1\n",
       "JerkOffToCelebs         1\n",
       "arresteddevelopment     1\n",
       "u_sarah-xxx             1\n",
       "uwotm8                  1\n",
       "KahoShibuya             1\n",
       "Yosemite                1\n",
       "simpleliving            1\n",
       "me_ira                  1\n",
       "punchableface           1\n",
       "holdmycatnip            1\n",
       "datgap                  1\n",
       "trashyboners            1\n",
       "conspiratard            1\n",
       "DisneyEyes              1\n",
       "FFNBPS                  1\n",
       "ImaginaryBehemoths      1\n",
       "ArtPorn                 1\n",
       "NintendoSwitchDeals     1\n",
       "Ebony                   1\n",
       "ShitLiberalsSay         1\n",
       "savedyouaclick          1\n",
       "GarlicBreadMemes        1\n",
       "lost                    1\n",
       "JordanPeterson          1\n",
       "Seattle                 1\n",
       "MilitaryStories         1\n",
       "Gunime                  1\n",
       "Name: subreddit, Length: 2446, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['subreddit_other'] = [subred if (data['subreddit'] == subred).sum() > 3 else 'other' for subred in data['subreddit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                   2842\n",
       "politics                  11\n",
       "funny                      9\n",
       "todayilearned              9\n",
       "aww                        8\n",
       "GlobalOffensive            8\n",
       "Animemes                   8\n",
       "Rainbow6                   8\n",
       "BlackPeopleTwitter         8\n",
       "Overwatch                  8\n",
       "me_irl                     8\n",
       "AskReddit                  8\n",
       "dankmemes                  8\n",
       "soccer                     8\n",
       "pics                       8\n",
       "nba                        8\n",
       "gaming                     8\n",
       "gifs                       8\n",
       "oddlysatisfying            7\n",
       "greentext                  7\n",
       "worldnews                  7\n",
       "FortNiteBR                 7\n",
       "PeopleFuckingDying         7\n",
       "SquaredCircle              7\n",
       "news                       7\n",
       "memes                      7\n",
       "tumblr                     7\n",
       "MonsterHunter              7\n",
       "DDLC                       7\n",
       "FireEmblemHeroes           7\n",
       "                        ... \n",
       "Iota                       4\n",
       "Dachshund                  4\n",
       "esist                      4\n",
       "MovieDetails               4\n",
       "StreetFighter              4\n",
       "IDontWorkHereLady          4\n",
       "Gunpla                     4\n",
       "barstoolsports             4\n",
       "chelseafc                  4\n",
       "GirlsFinishingTheJob       4\n",
       "chubby                     4\n",
       "DarlingInTheFranxx         4\n",
       "CollegeBasketball          4\n",
       "Romania                    4\n",
       "AskMen                     4\n",
       "GetMotivated               4\n",
       "witcher                    4\n",
       "drawing                    4\n",
       "india                      4\n",
       "OnePiece                   4\n",
       "doctorwho                  4\n",
       "AbandonedPorn              4\n",
       "motorcycles                4\n",
       "Bondage                    4\n",
       "teslamotors                4\n",
       "gonewildcolor              4\n",
       "RedditLaqueristas          4\n",
       "gonewildcurvy              4\n",
       "Paladins                   4\n",
       "nintendo                   4\n",
       "Name: subreddit_other, Length: 444, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['subreddit_other'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of the CategoricalEncoder class, copied from PR #9151.\n",
    "# Just run this cell, or copy it to your code, do not try to understand it (yet).\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Encode categorical features as a numeric array.\n",
    "    The input to this transformer should be a matrix of integers or strings,\n",
    "    denoting the values taken on by categorical (discrete) features.\n",
    "    The features can be encoded using a one-hot aka one-of-K scheme\n",
    "    (``encoding='onehot'``, the default) or converted to ordinal integers\n",
    "    (``encoding='ordinal'``).\n",
    "    This encoding is needed for feeding categorical data to many scikit-learn\n",
    "    estimators, notably linear models and SVMs with the standard kernels.\n",
    "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n",
    "        The type of encoding to use (default is 'onehot'):\n",
    "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n",
    "          (or also called 'dummy' encoding). This creates a binary column for\n",
    "          each category and returns a sparse matrix.\n",
    "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n",
    "          instead of a sparse matrix.\n",
    "        - 'ordinal': encode the features as ordinal integers. This results in\n",
    "          a single column of integers (0 to n_categories - 1) per feature.\n",
    "    categories : 'auto' or a list of lists/arrays of values.\n",
    "        Categories (unique values) per feature:\n",
    "        - 'auto' : Determine categories automatically from the training data.\n",
    "        - list : ``categories[i]`` holds the categories expected in the ith\n",
    "          column. The passed categories are sorted before encoding the data\n",
    "          (used categories can be found in the ``categories_`` attribute).\n",
    "    dtype : number type, default np.float64\n",
    "        Desired dtype of output.\n",
    "    handle_unknown : 'error' (default) or 'ignore'\n",
    "        Whether to raise an error or ignore if a unknown categorical feature is\n",
    "        present during transform (default is to raise). When this is parameter\n",
    "        is set to 'ignore' and an unknown category is encountered during\n",
    "        transform, the resulting one-hot encoded columns for this feature\n",
    "        will be all zeros.\n",
    "        Ignoring unknown categories is not supported for\n",
    "        ``encoding='ordinal'``.\n",
    "    Attributes\n",
    "    ----------\n",
    "    categories_ : list of arrays\n",
    "        The categories of each feature determined during fitting. When\n",
    "        categories were specified manually, this holds the sorted categories\n",
    "        (in order corresponding with output of `transform`).\n",
    "    Examples\n",
    "    --------\n",
    "    Given a dataset with three features and two samples, we let the encoder\n",
    "    find the maximum value per feature and transform the data to a binary\n",
    "    one-hot encoding.\n",
    "    >>> from sklearn.preprocessing import CategoricalEncoder\n",
    "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n",
    "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
    "    ... # doctest: +ELLIPSIS\n",
    "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n",
    "              encoding='onehot', handle_unknown='ignore')\n",
    "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n",
    "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n",
    "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n",
    "      features take on values in the range ``[0, max(feature)]`` instead of\n",
    "      using the unique values.\n",
    "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
    "      dictionary items (also handles string-valued features).\n",
    "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
    "      encoding of dictionary items or strings.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
    "                 handle_unknown='error'):\n",
    "        self.encoding = encoding\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "        self.handle_unknown = handle_unknown\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the CategoricalEncoder to X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_feature]\n",
    "            The data to determine the categories of each feature.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
    "                        \"or 'ordinal', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "        if self.handle_unknown not in ['error', 'ignore']:\n",
    "            template = (\"handle_unknown should be either 'error' or \"\n",
    "                        \"'ignore', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
    "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
    "                             \" encoding='ordinal'\")\n",
    "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders_[i]\n",
    "            Xi = X[:, i]\n",
    "            if self.categories == 'auto':\n",
    "                le.fit(Xi)\n",
    "            else:\n",
    "                valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(Xi[~valid_mask])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during fit\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform X using one-hot encoding.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to encode.\n",
    "        Returns\n",
    "        -------\n",
    "        X_out : sparse matrix or a 2-d array\n",
    "            Transformed input.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_int = np.zeros_like(X, dtype=np.int)\n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == 'error':\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                           \" during transform\".format(diff, i))\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    # Set the problematic rows to an acceptable value and\n",
    "                    # continue `The rows are marked `X_mask` and will be\n",
    "                    # removed later.\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "        if self.encoding == 'ordinal':\n",
    "            return X_int.astype(self.dtype, copy=False)\n",
    "        mask = X_mask.ravel()\n",
    "        n_values = [cats.shape[0] for cats in self.categories_]\n",
    "        n_values = np.array([0] + n_values)\n",
    "        indices = np.cumsum(n_values)\n",
    "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                n_features)[mask]\n",
    "        data = np.ones(n_samples * n_features)[mask]\n",
    "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                shape=(n_samples, indices[-1]),\n",
    "                                dtype=self.dtype).tocsr()\n",
    "        if self.encoding == 'onehot-dense':\n",
    "            return out.toarray()\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ce = CategoricalEncoder(encoding='onehot-dense',handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_var_df = ce.fit_transform(data['subreddit_other'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_var_df = pd.DataFrame(dummy_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>434</th>\n",
       "      <th>435</th>\n",
       "      <th>436</th>\n",
       "      <th>437</th>\n",
       "      <th>438</th>\n",
       "      <th>439</th>\n",
       "      <th>440</th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   434  435  436  437  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.0   \n",
       "\n",
       "   438  439  440  441  442  443  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 444 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_var_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['popular'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971, 444)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_var_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Train/Test Split\n",
    "y = data['popular']\n",
    "X = dummy_var_df\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.5, random_state=142)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearch\n",
      "{'n_estimators': 1000, 'min_samples_split': 40, 'min_samples_leaf': 3, 'max_features': 50, 'max_depth': 25}\n",
      "0.609657947686\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=25, max_features=50, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=40,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.622687047466\n",
      "CPU times: user 7.02 s, sys: 119 ms, total: 7.14 s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#RandomizeSearchCV to find best parameters\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params =  {\"max_depth\": [10,15,25]\n",
    "            ,\"min_samples_split\" :range(20,100,10)\n",
    "            ,\"min_samples_leaf\": range(1,10,2)\n",
    "            ,\"n_estimators\" : [50,1000, 2500]\n",
    "            ,\"max_features\": (4,50, \"sqrt\")\n",
    "             }\n",
    "\n",
    "\n",
    "randomsearch = RandomizedSearchCV(RandomForestClassifier(), params, cv=5, \n",
    "                                      n_iter=10, verbose=1, n_jobs=2, random_state=42)\n",
    "\n",
    "randomsearch = randomsearch.fit(X_train, y_train)\n",
    "learned_parameters =randomsearch.best_params_\n",
    "\n",
    "print('RandomizedSearch')\n",
    "print(randomsearch.best_params_)\n",
    "print(randomsearch.best_score_)\n",
    "print(randomsearch.best_estimator_)\n",
    "print(randomsearch.best_estimator_.score(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.632595573441\n",
      "Test Accuracy  :  0.621078037007\n",
      "Confusion matrix :  [[871 349]\n",
      " [593 673]]\n",
      "[  4.66276310e-03   0.00000000e+00   7.94528802e-04   0.00000000e+00\n",
      "   6.12670576e-05   0.00000000e+00   1.64091604e-03   0.00000000e+00\n",
      "   3.43883397e-03   1.03530716e-05   0.00000000e+00   4.32615961e-03\n",
      "   0.00000000e+00   4.23809629e-03   0.00000000e+00   1.20021448e-02\n",
      "   6.76838762e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.98069581e-03   1.52623302e-03   1.26991026e-02\n",
      "   0.00000000e+00   4.68867002e-03   0.00000000e+00   0.00000000e+00\n",
      "   5.96120253e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   7.48854141e-06   4.61315301e-03   0.00000000e+00   6.50920008e-03\n",
      "   0.00000000e+00   0.00000000e+00   4.37791756e-06   2.84933824e-05\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.68672291e-03\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   8.36806701e-03   7.70160805e-04   0.00000000e+00   0.00000000e+00\n",
      "   7.47649165e-04   7.71248538e-04   0.00000000e+00   0.00000000e+00\n",
      "   8.58882540e-03   2.02691253e-05   0.00000000e+00   0.00000000e+00\n",
      "   4.57520820e-03   0.00000000e+00   8.67247366e-04   2.07304857e-05\n",
      "   0.00000000e+00   0.00000000e+00   6.54195551e-04   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   7.22989521e-04\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   7.61182462e-04\n",
      "   8.18757345e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   1.47580498e-03   0.00000000e+00   0.00000000e+00   7.65372461e-04\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.85277321e-04   7.57436102e-04   1.37439818e-02\n",
      "   6.50788433e-03   0.00000000e+00   7.59554257e-04   0.00000000e+00\n",
      "   0.00000000e+00   6.14079391e-04   6.46797181e-04   0.00000000e+00\n",
      "   6.26987718e-03   2.83542074e-05   0.00000000e+00   0.00000000e+00\n",
      "   1.82578737e-03   1.63792178e-03   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.48660095e-03   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.84918939e-03   1.67516890e-03   1.56304680e-03\n",
      "   0.00000000e+00   6.29845322e-03   6.77424163e-04   1.44217842e-03\n",
      "   5.34948917e-03   0.00000000e+00   0.00000000e+00   8.11464685e-03\n",
      "   1.26634685e-03   0.00000000e+00   4.08318585e-05   4.24761585e-03\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   4.85981936e-03   7.20252408e-04   0.00000000e+00   0.00000000e+00\n",
      "   7.77832151e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   6.56398529e-04   6.60329215e-03   0.00000000e+00   0.00000000e+00\n",
      "   4.47764071e-03   0.00000000e+00   6.11533551e-04   7.03830915e-04\n",
      "   4.20029760e-03   7.22382307e-04   5.00766819e-03   0.00000000e+00\n",
      "   7.48920372e-04   0.00000000e+00   1.54949687e-05   0.00000000e+00\n",
      "   1.29267682e-03   4.57617679e-03   5.65588481e-03   7.62299438e-04\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.67124532e-03\n",
      "   0.00000000e+00   1.70771732e-03   0.00000000e+00   3.92262501e-04\n",
      "   2.62225914e-05   0.00000000e+00   5.70715240e-05   0.00000000e+00\n",
      "   0.00000000e+00   1.32728041e-02   0.00000000e+00   0.00000000e+00\n",
      "   2.60138295e-06   0.00000000e+00   5.24237623e-03   2.98853059e-05\n",
      "   0.00000000e+00   3.62166022e-05   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.75124282e-03   1.58211849e-03   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   5.61797836e-03\n",
      "   0.00000000e+00   0.00000000e+00   8.60654247e-03   0.00000000e+00\n",
      "   6.18900712e-05   0.00000000e+00   0.00000000e+00   6.69244518e-06\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   1.22842313e-02\n",
      "   0.00000000e+00   0.00000000e+00   1.40849847e-03   1.56019570e-03\n",
      "   0.00000000e+00   0.00000000e+00   4.56969040e-03   0.00000000e+00\n",
      "   0.00000000e+00   7.33357849e-04   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   6.62376251e-04   6.70104700e-04\n",
      "   0.00000000e+00   0.00000000e+00   7.69345214e-04   0.00000000e+00\n",
      "   5.27372776e-05   0.00000000e+00   2.40493003e-05   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.51976097e-04   0.00000000e+00   1.41192343e-02\n",
      "   0.00000000e+00   0.00000000e+00   6.40061606e-03   7.38509156e-04\n",
      "   5.86870349e-03   0.00000000e+00   0.00000000e+00   8.36635312e-04\n",
      "   0.00000000e+00   1.37773742e-03   1.63355584e-03   0.00000000e+00\n",
      "   3.64901023e-05   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   7.32030338e-04   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   7.16096573e-04   4.47796552e-03   0.00000000e+00   4.93084948e-03\n",
      "   0.00000000e+00   1.68805336e-03   0.00000000e+00   0.00000000e+00\n",
      "   4.78801438e-03   1.75600681e-03   8.05328268e-03   0.00000000e+00\n",
      "   7.50093196e-04   4.15529483e-05   2.13406410e-02   0.00000000e+00\n",
      "   7.16368268e-04   8.05175869e-04   0.00000000e+00   8.13371345e-03\n",
      "   0.00000000e+00   1.51296012e-03   2.21518923e-03   4.53505125e-03\n",
      "   7.74059585e-04   0.00000000e+00   4.30135779e-03   0.00000000e+00\n",
      "   0.00000000e+00   4.72428619e-03   0.00000000e+00   1.34413982e-03\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   6.12041088e-04\n",
      "   0.00000000e+00   6.03432451e-03   1.54150233e-03   5.18262481e-05\n",
      "   0.00000000e+00   7.00035596e-04   0.00000000e+00   3.47538594e-05\n",
      "   4.19756079e-03   1.68518549e-03   4.52772005e-03   2.33168538e-05\n",
      "   0.00000000e+00   4.43421683e-03   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.62636365e-03   4.76058923e-03   4.45161991e-03\n",
      "   0.00000000e+00   0.00000000e+00   1.73397759e-03   8.56933417e-04\n",
      "   1.77758662e-03   0.00000000e+00   0.00000000e+00   3.00597450e-05\n",
      "   5.91919114e-04   0.00000000e+00   4.33731507e-04   5.07528805e-03\n",
      "   5.85999368e-04   0.00000000e+00   6.02985439e-03   0.00000000e+00\n",
      "   0.00000000e+00   1.69644368e-03   0.00000000e+00   0.00000000e+00\n",
      "   8.77917576e-03   0.00000000e+00   1.81752279e-03   4.50178851e-03\n",
      "   3.89398095e-05   6.98058848e-04   0.00000000e+00   1.42930720e-02\n",
      "   3.52275846e-05   2.06372436e-05   0.00000000e+00   1.67807817e-03\n",
      "   0.00000000e+00   0.00000000e+00   8.23586259e-06   4.33950832e-01\n",
      "   0.00000000e+00   6.19037122e-03   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   8.42699341e-03   0.00000000e+00   2.61796523e-06\n",
      "   5.48564436e-05   6.77122070e-04   0.00000000e+00   0.00000000e+00\n",
      "   8.30812821e-04   0.00000000e+00   7.85280021e-04   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   6.22995190e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   6.43766117e-03   1.23724107e-05   9.17633253e-03   6.66713239e-04\n",
      "   0.00000000e+00   0.00000000e+00   5.42238770e-04   0.00000000e+00\n",
      "   4.58992489e-03   6.85447291e-04   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   4.65899248e-04   0.00000000e+00   6.04366387e-03   0.00000000e+00\n",
      "   0.00000000e+00   6.86845491e-04   1.76338736e-03   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   1.53438401e-03   1.56387545e-03\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   1.17782963e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.78581189e-03   1.49178948e-03   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   4.74110382e-03   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   5.76769321e-04   0.00000000e+00   1.57102980e-03\n",
      "   3.96379636e-03   6.07361781e-03   4.96776477e-03   0.00000000e+00]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.71      0.65      1220\n",
      "          1       0.66      0.53      0.59      1266\n",
      "\n",
      "avg / total       0.63      0.62      0.62      2486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier with best_param\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = learned_parameters[\"max_depth\"]\n",
    "                            ,max_features= learned_parameters['max_features']\n",
    "                            ,min_samples_leaf= learned_parameters['min_samples_leaf']\n",
    "                            ,min_samples_split= learned_parameters['min_samples_split']\n",
    "                            ,n_estimators= learned_parameters[\"n_estimators\"]\n",
    "                            )\n",
    "\n",
    "model = rfc.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print (\"Train Accuracy : \", accuracy_score(y_train, model.predict(X_train)))\n",
    "print (\"Test Accuracy  : \", accuracy_score(y_test, predictions))\n",
    "print (\"Confusion matrix : \", confusion_matrix(y_test, predictions))\n",
    "print (rfc.feature_importances_)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a thread title.\n",
    "- For example, create a feature that represents whether 'cat' is in the title or whether 'funny' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the thread titles.\n",
    "- Build a new random forest model with subreddit and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a feature that represents whether 'cat' is in the title or whether 'funny' is in the title.\n",
    "\n",
    "# if 'cat' is in the title\n",
    "data['cat'] = [1 if 'cat' in x else 0 for x in data['title']]\n",
    "\n",
    "# if 'funny' is in the title\n",
    "data['funny'] = [1 if 'funny' in x else 0 for x in data['title']]\n",
    "\n",
    "# if 'love' is in the title\n",
    "data['love'] = [1 if 'love' in x else 0 for x in data['title']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4911\n",
       "1      60\n",
       "Name: cat, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4966\n",
       "1       5\n",
       "Name: funny, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['funny'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4912\n",
       "1      59\n",
       "Name: love, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['love'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   23.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearch\n",
      "{'n_estimators': 50, 'min_samples_split': 40, 'min_samples_leaf': 5, 'max_features': 1, 'max_depth': 10}\n",
      "0.507444668008\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features=1, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=5, min_samples_split=40,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.508447304907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   23.8s finished\n"
     ]
    }
   ],
   "source": [
    "#Then build a new Random Forest with these features. \n",
    "\n",
    "y = data['popular']\n",
    "X = data [['cat','funny', 'love']]\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.5, random_state=142)\n",
    "\n",
    "\n",
    "#Find best param\n",
    "\n",
    "\n",
    "params =  {\"max_depth\": [10,15,25]\n",
    "            ,\"min_samples_split\" :range(20,100,10)\n",
    "            ,\"min_samples_leaf\": range(1,10,2)\n",
    "            ,\"n_estimators\" : [50,1000, 2500]\n",
    "            ,\"max_features\": (1,\"sqrt\")\n",
    "             }\n",
    "\n",
    "\n",
    "randomsearch = RandomizedSearchCV(RandomForestClassifier(), params, cv=5, \n",
    "                                      n_iter=10, verbose=1, n_jobs=2, random_state=42)\n",
    "\n",
    "randomsearch = randomsearch.fit(X_train, y_train)\n",
    "learned_parameters =randomsearch.best_params_\n",
    "\n",
    "print('RandomizedSearch')\n",
    "print(randomsearch.best_params_)\n",
    "print(randomsearch.best_score_)\n",
    "print(randomsearch.best_estimator_)\n",
    "print(randomsearch.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.507444668008\n",
      "Test Accuracy  :  0.508447304907\n",
      "Confusion matrix :  [[  12 1208]\n",
      " [  14 1252]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.46      0.01      0.02      1220\n",
      "          1       0.51      0.99      0.67      1266\n",
      "\n",
      "avg / total       0.49      0.51      0.35      2486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting with learned params\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = learned_parameters[\"max_depth\"]\n",
    "                            ,max_features= learned_parameters['max_features']\n",
    "                            ,min_samples_leaf= learned_parameters['min_samples_leaf']\n",
    "                            ,min_samples_split= learned_parameters['min_samples_split']\n",
    "                            ,n_estimators= learned_parameters[\"n_estimators\"]\n",
    "                            )\n",
    "\n",
    "model = rfc.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print (\"Train Accuracy : \", accuracy_score(y_train, model.predict(X_train)))\n",
    "print (\"Test Accuracy  : \", accuracy_score(y_test, predictions))\n",
    "print (\"Confusion matrix : \", confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0003571</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>017</th>\n",
       "      <th>02</th>\n",
       "      <th>04</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>...</th>\n",
       "      <th>år</th>\n",
       "      <th>æternam</th>\n",
       "      <th>èze</th>\n",
       "      <th>última</th>\n",
       "      <th>świata</th>\n",
       "      <th>šejić</th>\n",
       "      <th>ƃuoʎuuɐ</th>\n",
       "      <th>ネヲ</th>\n",
       "      <th>로제</th>\n",
       "      <th>위키미키</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0003571  00pm  01  017  02  04  07  08  ...   år  æternam  èze  \\\n",
       "0   0    0        0     0   0    0   0   0   0   0  ...    0        0    0   \n",
       "1   0    0        0     0   0    0   0   0   0   0  ...    0        0    0   \n",
       "2   0    0        0     0   0    0   0   0   0   0  ...    0        0    0   \n",
       "3   0    0        0     0   0    0   0   0   0   0  ...    0        0    0   \n",
       "4   0    0        0     0   0    0   0   0   0   0  ...    0        0    0   \n",
       "\n",
       "   última  świata  šejić  ƃuoʎuuɐ  ネヲ  로제  위키미키  \n",
       "0       0       0      0        0   0   0     0  \n",
       "1       0       0      0        0   0   0     0  \n",
       "2       0       0      0        0   0   0     0  \n",
       "3       0       0      0        0   0   0     0  \n",
       "4       0       0      0        0   0   0     0  \n",
       "\n",
       "[5 rows x 10569 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count Vectorizer to create features based on the words in the thread titles.\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(data['title'])\n",
    "cvecdata = cvec.transform(data['title'])\n",
    "\n",
    "dfcv  = pd.DataFrame(cvecdata.todense(), columns=cvec.get_feature_names())\n",
    "dfcv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971, 10569)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(dfcv.sum(axis=0).sort_values(ascending=False).head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "just      168\n",
       "new       160\n",
       "like      106\n",
       "time       98\n",
       "today      81\n",
       "got        79\n",
       "day        79\n",
       "good       74\n",
       "people     60\n",
       "don        59\n",
       "old        57\n",
       "best       57\n",
       "love       53\n",
       "little     53\n",
       "think      52\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = cvec.get_feature_names()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearch\n",
      "{'n_estimators': 50, 'min_samples_split': 40, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 15}\n",
      "0.539235412475\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=15, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=40,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.516090104586\n"
     ]
    }
   ],
   "source": [
    "#Build a model with the CountVectorizer feature\n",
    "\n",
    "y = data['popular']\n",
    "X = dfcv\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.5, random_state=142)\n",
    "\n",
    "#Find best param\n",
    "\n",
    "\n",
    "params =  {\"max_depth\": [10,15,25]\n",
    "            ,\"min_samples_split\" :range(20,100,10)\n",
    "            ,\"min_samples_leaf\": range(1,10,2)\n",
    "            ,\"n_estimators\" : [50,1000, 2500]\n",
    "            ,\"max_features\": (5,\"sqrt\")\n",
    "             }\n",
    "\n",
    "\n",
    "randomsearch = RandomizedSearchCV(RandomForestClassifier(), params, cv=5, \n",
    "                                      n_iter=10, verbose=1, n_jobs=2, random_state=42)\n",
    "\n",
    "randomsearch = randomsearch.fit(X_train, y_train)\n",
    "learned_parameters =randomsearch.best_params_\n",
    "\n",
    "print('RandomizedSearch')\n",
    "print(randomsearch.best_params_)\n",
    "print(randomsearch.best_score_)\n",
    "print(randomsearch.best_estimator_)\n",
    "print(randomsearch.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.668812877264\n",
      "Test Accuracy  :  0.566773934031\n",
      "Confusion matrix :  [[842 378]\n",
      " [699 567]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.69      0.61      1220\n",
      "          1       0.60      0.45      0.51      1266\n",
      "\n",
      "avg / total       0.57      0.57      0.56      2486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting with learned params\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = learned_parameters[\"max_depth\"]\n",
    "                            ,max_features= learned_parameters['max_features']\n",
    "                            ,min_samples_leaf= learned_parameters['min_samples_leaf']\n",
    "                            ,min_samples_split= learned_parameters['min_samples_split']\n",
    "                            ,n_estimators= learned_parameters[\"n_estimators\"]\n",
    "                            )\n",
    "\n",
    "model = rfc.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print (\"Train Accuracy : \", accuracy_score(y_train, model.predict(X_train)))\n",
    "print (\"Test Accuracy  : \", accuracy_score(y_test, predictions))\n",
    "print (\"Confusion matrix : \", confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_var_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['funny'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['love'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dummy_var_df, data['cat'], data['funny'], data['love'], dfcv]\n",
    "\n",
    "features_df = pd.concat(frames, axis=1, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971, 11016)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   58.3s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearch\n",
      "{'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "0.602816901408\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=20,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.631134352373\n"
     ]
    }
   ],
   "source": [
    "y = data['popular']\n",
    "X = features_df\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.5, random_state=142)\n",
    "\n",
    "#Find best param\n",
    "\n",
    "\n",
    "params =  {\"max_depth\": [10,15,25]\n",
    "            ,\"min_samples_split\" :range(20,100,10)\n",
    "            ,\"min_samples_leaf\": range(1,10,2)\n",
    "            ,\"n_estimators\" : [50,1000, 2500]\n",
    "            ,\"max_features\": (5,\"sqrt\")\n",
    "             }\n",
    "\n",
    "\n",
    "randomsearch = RandomizedSearchCV(RandomForestClassifier(), params, cv=5, \n",
    "                                      n_iter=10, verbose=1, n_jobs=2, random_state=42)\n",
    "\n",
    "randomsearch = randomsearch.fit(X_train, y_train)\n",
    "learned_parameters =randomsearch.best_params_\n",
    "\n",
    "print('RandomizedSearch')\n",
    "print(randomsearch.best_params_)\n",
    "print(randomsearch.best_score_)\n",
    "print(randomsearch.best_estimator_)\n",
    "print(randomsearch.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.701810865191\n",
      "Test Accuracy  :  0.633547868061\n",
      "Confusion matrix :  [[756 464]\n",
      " [447 819]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.62      0.62      1220\n",
      "          1       0.64      0.65      0.64      1266\n",
      "\n",
      "avg / total       0.63      0.63      0.63      2486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting with learned params\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = learned_parameters[\"max_depth\"]\n",
    "                            ,max_features= learned_parameters['max_features']\n",
    "                            ,min_samples_leaf= learned_parameters['min_samples_leaf']\n",
    "                            ,min_samples_split= learned_parameters['min_samples_split']\n",
    "                            ,n_estimators= learned_parameters[\"n_estimators\"]\n",
    "                            )\n",
    "\n",
    "model = rfc.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print (\"Train Accuracy : \", accuracy_score(y_train, model.predict(X_train)))\n",
    "print (\"Test Accuracy  : \", accuracy_score(y_test, predictions))\n",
    "print (\"Confusion matrix : \", confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "\n",
    "y = data['popular']\n",
    "X = features_df\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=41)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "model = rfc.fit(X, y)\n",
    "\n",
    "s = cross_val_score(rfc, X, y, cv=cv, n_jobs=-1)\n",
    "print(\"{} Score:\\t{:0.3} ± {:0.3}\".format(\"Random Forest\", s.mean().round(3), s.std().round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.95814889336\n",
      "Test Accuracy  :  0.635559131134\n",
      "Confusion matrix :  [[839 381]\n",
      " [525 741]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.69      0.65      1220\n",
      "          1       0.66      0.59      0.62      1266\n",
      "\n",
      "avg / total       0.64      0.64      0.63      2486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = data['popular']\n",
    "X = features_df\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.5, random_state=142)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "model = logreg.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "print (\"Train Accuracy : \", accuracy_score(y_train, model.predict(X_train)))\n",
    "print (\"Test Accuracy  : \", accuracy_score(y_test, predictions))\n",
    "print (\"Confusion matrix : \", confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Use Count Vectorizer from scikit-learn to create features from the thread titles. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = data['title'][0]\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['title_len'] = [len(x) for x in data['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32     96\n",
       "15     90\n",
       "27     90\n",
       "17     90\n",
       "25     89\n",
       "19     87\n",
       "21     86\n",
       "18     85\n",
       "31     80\n",
       "23     80\n",
       "37     79\n",
       "41     78\n",
       "14     77\n",
       "12     75\n",
       "33     75\n",
       "29     74\n",
       "16     73\n",
       "26     73\n",
       "20     72\n",
       "11     72\n",
       "22     72\n",
       "39     70\n",
       "38     70\n",
       "24     70\n",
       "36     67\n",
       "13     64\n",
       "30     64\n",
       "40     62\n",
       "34     60\n",
       "9      59\n",
       "       ..\n",
       "267     1\n",
       "258     1\n",
       "242     1\n",
       "233     1\n",
       "273     1\n",
       "237     1\n",
       "228     1\n",
       "241     1\n",
       "216     1\n",
       "204     1\n",
       "249     1\n",
       "253     1\n",
       "265     1\n",
       "188     1\n",
       "269     1\n",
       "180     1\n",
       "279     1\n",
       "238     1\n",
       "150     1\n",
       "154     1\n",
       "152     1\n",
       "174     1\n",
       "217     1\n",
       "140     1\n",
       "186     1\n",
       "260     1\n",
       "226     1\n",
       "230     1\n",
       "234     1\n",
       "299     1\n",
       "Name: title_len, Length: 253, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447     300\n",
       "4       300\n",
       "710     299\n",
       "1540    298\n",
       "3243    298\n",
       "285     298\n",
       "10      297\n",
       "2806    297\n",
       "1385    296\n",
       "4327    296\n",
       "546     294\n",
       "3337    294\n",
       "3922    294\n",
       "1654    294\n",
       "548     294\n",
       "282     294\n",
       "2172    294\n",
       "4079    292\n",
       "1304    288\n",
       "2549    288\n",
       "2575    286\n",
       "157     279\n",
       "4422    276\n",
       "3413    275\n",
       "4192    275\n",
       "3025    273\n",
       "3124    270\n",
       "4088    270\n",
       "2588    269\n",
       "143     267\n",
       "       ... \n",
       "1936      4\n",
       "108       4\n",
       "4251      4\n",
       "4223      4\n",
       "1880      4\n",
       "1483      3\n",
       "1626      3\n",
       "1953      3\n",
       "1356      3\n",
       "734       3\n",
       "3362      3\n",
       "2228      3\n",
       "1823      3\n",
       "2230      3\n",
       "380       3\n",
       "1535      3\n",
       "1806      3\n",
       "246       3\n",
       "3837      3\n",
       "379       3\n",
       "292       3\n",
       "49        3\n",
       "1026      3\n",
       "1737      3\n",
       "4288      3\n",
       "4491      2\n",
       "988       2\n",
       "4040      2\n",
       "877       2\n",
       "1579      1\n",
       "Name: title_len, Length: 4971, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['title_len'].sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [data['title_len'], dfcv]\n",
    "\n",
    "my_features = pd.concat(frames, axis=1, ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4971, 10570)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:   50.3s\n",
      "[Parallel(n_jobs=2)]: Done  50 out of  50 | elapsed:   52.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearch\n",
      "{'n_estimators': 1000, 'min_samples_split': 20, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 10}\n",
      "0.581488933602\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=3, min_samples_split=20,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "0.612228479485\n"
     ]
    }
   ],
   "source": [
    "#Build a model with tittle length and words in title\n",
    "\n",
    "y = data['popular']\n",
    "X = my_features\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.5, random_state=142)\n",
    "\n",
    "#Find best param\n",
    "\n",
    "\n",
    "params =  {\"max_depth\": [10,15,25]\n",
    "            ,\"min_samples_split\" :range(20,100,10)\n",
    "            ,\"min_samples_leaf\": range(1,10,2)\n",
    "            ,\"n_estimators\" : [50,1000, 2500]\n",
    "            ,\"max_features\": (5,\"sqrt\")\n",
    "             }\n",
    "\n",
    "\n",
    "randomsearch = RandomizedSearchCV(RandomForestClassifier(), params, cv=5, \n",
    "                                      n_iter=10, verbose=1, n_jobs=2, random_state=42)\n",
    "\n",
    "randomsearch = randomsearch.fit(X_train, y_train)\n",
    "learned_parameters =randomsearch.best_params_\n",
    "\n",
    "print('RandomizedSearch')\n",
    "print(randomsearch.best_params_)\n",
    "print(randomsearch.best_score_)\n",
    "print(randomsearch.best_estimator_)\n",
    "print(randomsearch.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.671227364185\n",
      "Test Accuracy  :  0.615848753017\n",
      "Confusion matrix :  [[578 642]\n",
      " [313 953]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.47      0.55      1220\n",
      "          1       0.60      0.75      0.67      1266\n",
      "\n",
      "avg / total       0.62      0.62      0.61      2486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Fitting with learned params\n",
    "\n",
    "rfc = RandomForestClassifier(max_depth = learned_parameters[\"max_depth\"]\n",
    "                            ,max_features= learned_parameters['max_features']\n",
    "                            ,min_samples_leaf= learned_parameters['min_samples_leaf']\n",
    "                            ,min_samples_split= learned_parameters['min_samples_split']\n",
    "                            ,n_estimators= learned_parameters[\"n_estimators\"]\n",
    "                            )\n",
    "\n",
    "model = rfc.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print (\"Train Accuracy : \", accuracy_score(y_train, model.predict(X_train)))\n",
    "print (\"Test Accuracy  : \", accuracy_score(y_test, predictions))\n",
    "print (\"Confusion matrix : \", confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "---\n",
    "Put your executive summary in a Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXECUTIVE SUMMARY\n",
    "\n",
    "\n",
    "The purpose of this report is to summarize the Data Acquisition processing, the implemented machine learning Classification modeling with Natural Language Processing techniques, and all corresponding Data Analyses used to build a binary predictor to investigate \"How to create a Reddit post that will get the most engagement from Reddit users\". \n",
    "For the first step, the Data Acquisition process, two different method were used: Web Scrapping and PRAW (The Python Reddit API Wrapper). For both methods four pieces of information were collected about the 'hot' threads listed on the Reddit homepage (www.reddit.com): \n",
    "1.\tThe title of the thread\n",
    "2.\tThe subreddit that the thread corresponds to\n",
    "3.\tThe length of time it has been up on Reddit\n",
    "4.\tThe number of comments on the thread\n",
    "After Web Scrapping 5000 threats, only 10% were non-duplicate data, that is when PRAW was used to collect the data sample. At the end of cleaning the dataset included: 4779 observations split in 2446 subreddits, with their corresponding number of comments, numbers of votes and date created.\n",
    "\n",
    "The specific problem statement is: What characteristics of a post on Reddit are most predictive of the overall interaction on a thread (as measured by number of comments)? Once we've got the data, we built a model that predicts whether or not a given Reddit post will have above or below the median number of comments. \n",
    "Since we want to predict a binary variable, whether the number of comments was low or high, we created a new binary variable (called 'popular') that is true (1) when the number of comments is high (above the median), false (0) otherwise, and converted into a binary classification problem, by predicting two classes, HIGH vs LOW number of comments. For this binary classification problem, we modeled using RandomForest from sklearn and RandomizedSearchCV for feature selection.\n",
    "\n",
    "We built the model with different features and analyzed their performance.\n",
    "##### Only \"subreddit\": (2446 distinct subreddits): \n",
    "- Train Accuracy: 0.633 \n",
    "- Test Accuracy: 0.621 \n",
    "    \n",
    "##### Features that represents whether 'cat' or 'funny' or 'love' is in the title.\n",
    "We found that 'cat' was in 60 titles and was not present in 4911 titles,\n",
    "'funny' was in 5 titles and was not present in 4966 titles,\n",
    "'love' was in 59 titles and was not present in 4912 titles.\n",
    "- Train Accuracy: 0.507 \n",
    "- Test Accuracy: 0.508\n",
    "\n",
    "###### Features based on the words in the thread titles using Count-vectorizer, removing stop-words\n",
    "We found 10569 different words. \n",
    "- Train Accuracy: 0.669 \n",
    "- Test Accuracy: 0.567\n",
    "\n",
    "###### Using all above features together (subreddits, 'cat', 'funny', 'love' and words)\n",
    "- Train Accuracy: 0.702\n",
    "- Test Accuracy: 0.634\n",
    "\n",
    "###### Lastly, fitting the model with the words on the tittle and the length of the title \n",
    "- Train Accuracy: 0.671\n",
    "- Test Accuracy: 0.612\n",
    "\n",
    "In conclusion, the better result we got a better accuracy in predicting if a threat will have HIGH or LOW comments was 70% using: subreddits, 'cat', 'funny', 'love' and words, as predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS\n",
    "Refer to the README for the bonus parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
